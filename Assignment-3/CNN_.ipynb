{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "import os\n",
    "from sklearn import preprocessing, metrics\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import Tuple\n",
    "from dataclasses import dataclass\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class MnistDataLoader:\n",
    "    def __init__(self, data_folder_path):\n",
    "        self.data_folder_path = data_folder_path\n",
    "        self.train_file_name = 'train-images-idx3-ubyte.gz'\n",
    "        self.train_label_file_name = 'train-labels-idx1-ubyte.gz'\n",
    "        self.test_file_name = 't10k-images-idx3-ubyte.gz'\n",
    "        self.test_label_file_name = 't10k-labels-idx1-ubyte.gz'\n",
    "        self.data = dict()\n",
    "        self.size = 28\n",
    "        self.color_channel = 1\n",
    "        self.data_list = [\n",
    "            'train_images',\n",
    "            'train_labels',\n",
    "            'test_images',\n",
    "            'test_labels'\n",
    "        ]\n",
    "\n",
    "    def load_images(self, data_list_index, file_name):\n",
    "        images = gzip.open(os.path.join(self.data_folder_path, file_name), 'rb')\n",
    "        self.data[self.data_list[data_list_index]] = np.frombuffer(images.read(), dtype=np.uint8, offset=16).reshape(-1, self.size, self.size)\n",
    "        self.data[self.data_list[data_list_index]] = self.data[self.data_list[data_list_index]].reshape(self.data[self.data_list[data_list_index]].shape[0], self.size, self.size, self.color_channel).astype(np.float32)\n",
    "\n",
    "    def load_labels(self, data_list_index, file_name):\n",
    "        labels = gzip.open(os.path.join(self.data_folder_path, file_name), 'rb')\n",
    "        self.data[self.data_list[data_list_index]] = np.frombuffer(labels.read(), dtype=np.uint8, offset=8)\n",
    "        self.data[self.data_list[data_list_index]].resize(self.data[self.data_list[data_list_index]].shape[0],1)\n",
    "\n",
    "    def load_mnist(self):\n",
    "        self.load_images(data_list_index=0, file_name=self.train_file_name)\n",
    "        self.load_labels(data_list_index=1, file_name=self.train_label_file_name)\n",
    "        self.load_images(data_list_index=2, file_name=self.test_file_name)\n",
    "        self.load_labels(data_list_index=3, file_name=self.test_label_file_name)\n",
    "\n",
    "        self.assert_data_shape()\n",
    "\n",
    "    def assert_data_shape(self):\n",
    "        assert self.data[self.data_list[0]].shape == (60000, 28, 28, 1)\n",
    "        assert self.data[self.data_list[1]].shape == (60000, 1)\n",
    "        assert self.data[self.data_list[2]].shape == (10000, 28, 28, 1)\n",
    "        assert self.data[self.data_list[3]].shape == (10000, 1)\n",
    "\n",
    "    def preprocess_data(self):\n",
    "\n",
    "        self.data[self.data_list[0]] /= 255\n",
    "        self.data[self.data_list[2]] /= 255\n",
    "\n",
    "        self.data[self.data_list[1]] = Utility.one_hot_encode(self.data[self.data_list[1]])\n",
    "        self.data[self.data_list[3]] = Utility.one_hot_encode(self.data[self.data_list[3]])\n",
    "\n",
    "        assert self.data[self.data_list[1]].shape == (60000, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class Cifer10DataLoader:\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "        self.size = 32\n",
    "        self.color_channel = 3\n",
    "        self.per_batch_data_size = 10000\n",
    "        self.data = dict()\n",
    "\n",
    "    def load_data(self, file_name):\n",
    "        with open(os.path.join(self.data_path, file_name), 'rb') as f:\n",
    "\n",
    "            data_dict=pickle.load(f, encoding='latin1')\n",
    "\n",
    "            images = data_dict['data']\n",
    "            labels = data_dict['labels']\n",
    "\n",
    "            images = images.reshape(self.per_batch_data_size, self.color_channel, self.size, self.size).transpose(0,2,3,1).astype(\"float\")\n",
    "            labels = np.array(labels)\n",
    "            print(labels.shape)\n",
    "\n",
    "            return images, labels\n",
    "\n",
    "    def concatenate_data(self):\n",
    "        X1, Y1 = self.load_data('data_batch_1')\n",
    "        X2, Y2 = self.load_data('data_batch_2')\n",
    "        X3, Y3 = self.load_data('data_batch_3')\n",
    "        X4, Y4 = self.load_data('data_batch_4')\n",
    "        X5, Y5 = self.load_data('data_batch_5')\n",
    "\n",
    "        self.data['train_images'] = np.concatenate(\n",
    "            (\n",
    "                X1, X2, X3, X4, X5\n",
    "            ),\n",
    "            axis=0\n",
    "        )\n",
    "\n",
    "        self.data['train_labels'] = np.concatenate(\n",
    "            (\n",
    "                Y1.reshape(self.per_batch_data_size, 1),\n",
    "                Y2.reshape(self.per_batch_data_size, 1),\n",
    "                Y3.reshape(self.per_batch_data_size, 1),\n",
    "                Y4.reshape(self.per_batch_data_size, 1),\n",
    "                Y5.reshape(self.per_batch_data_size, 1)\n",
    "            ),\n",
    "            axis=0\n",
    "        )\n",
    "\n",
    "        X_test, Y_test = self.load_data('test_batch')\n",
    "\n",
    "        self.data['test_images'] = X_test\n",
    "        self.data['test_labels'] = Y_test.reshape(Y_test.shape[0], 1)\n",
    "\n",
    "        self.assert_data_shape()\n",
    "\n",
    "        for key, data in self.data.items():\n",
    "            print(f'Shape: {data.shape}')\n",
    "\n",
    "    def assert_data_shape(self):\n",
    "        assert self.data['train_images'].shape == (50000, 32, 32, 3)\n",
    "        assert self.data['train_labels'].shape == (50000, 1)\n",
    "        assert self.data['test_images'].shape  == (10000, 32, 32, 3)\n",
    "        assert self.data['test_labels'].shape  == (10000, 1)\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        self.data['train_images'] /= 255\n",
    "        self.data['test_images'] /= 255\n",
    "\n",
    "        self.data['train_labels'] = Utility.one_hot_encode(self.data['train_labels'])\n",
    "        self.data['test_labels'] = Utility.one_hot_encode(self.data['test_labels'])\n",
    "\n",
    "        assert self.data['train_labels'].shape == (50000, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convolution"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "class Convolution2D:\n",
    "\n",
    "    # class variable\n",
    "    layer_num = 1\n",
    "    file_name = 'weights.txt'\n",
    "\n",
    "    def __init__(self, num_out_channel, filter_size, stride, padding_size):\n",
    "        self.num_out_channel = num_out_channel\n",
    "        self.filter_size = filter_size\n",
    "        self.stride = stride\n",
    "        self.padding_size = padding_size\n",
    "        self.h_prev, self.w_prev, self.num_channel_prev = None, None, None\n",
    "        self.h_new, self.w_new = None, None\n",
    "        self.W = None\n",
    "        self.b = None\n",
    "        self.output_tensor = None\n",
    "        self.cache = {}\n",
    "        self.layer_name = 'Conv2D__' + str(self.__class__.layer_num)\n",
    "        self.__class__.layer_num += 1\n",
    "        self.is_trainable = True\n",
    "        self.training_mode = False\n",
    "        self.activation_prev_current_layer_cache = None\n",
    "\n",
    "        print('The layer name: ', self.layer_name, self.layer_num)\n",
    "\n",
    "    def toggle_training_mode(self):\n",
    "        if not self.training_mode:\n",
    "            self.training_mode = True\n",
    "        else:\n",
    "            self.training_mode = False\n",
    "\n",
    "    def initialize_output_dimensions(self, prev_layer_output_dim):\n",
    "        \"\"\"\n",
    "        Initializes output dimensions with the dimension of the previous layers\n",
    "        :param prev_layer_output_dim: output dimension of the layer immediately before this layer\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        self.h_prev, self.w_prev , self.num_channel_prev = prev_layer_output_dim\n",
    "        self.h_new = (self.h_prev - self.filter_size + 2 * self.padding_size) // self.stride + 1\n",
    "        self.w_new = (self.w_prev - self.filter_size + 2 * self.padding_size) // self.stride + 1\n",
    "\n",
    "    def initialize_weights_biases(self):\n",
    "        \"\"\"\n",
    "        Initializes weights with the proper dimensions\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        #print('he: parameters: ', (self.h_prev * self.w_prev * self.num_channel_prev))\n",
    "        self.W = np.random.randn(self.filter_size, self.filter_size, self.num_channel_prev, self.num_out_channel) * np.sqrt(2/(self.h_prev * self.w_prev * self.num_channel_prev))\n",
    "        self.b = np.zeros((1, 1, 1, self.num_out_channel))\n",
    "\n",
    "    def forward_wob(self, Z_prev, is_training):\n",
    "        \"\"\"\n",
    "        Performs a forward operation of the convolution layer\n",
    "        :param Z_prev: The activation of the previous layer\n",
    "        :param is_training: whether we are in training mode or not\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        assert Z_prev.shape == (self.h_prev, self.w_prev, self.num_channel_prev)\n",
    "        Z_prev = np.array(Z_prev, copy=True)\n",
    "\n",
    "        # create zero padded Z_prev\n",
    "        Z_prev_padded = Utility.zero_pad_without_batch(Z_prev, self.padding_size)\n",
    "        self.output_tensor = np.zeros((self.h_new, self.w_new, self.num_out_channel))\n",
    "\n",
    "        # Apply convolution operation over this zero padded previous activation\n",
    "        for row in range(self.h_new):\n",
    "\n",
    "            row_start = row * self.stride\n",
    "\n",
    "            for col in range(self.w_new):\n",
    "\n",
    "                col_start = col *  self.stride\n",
    "\n",
    "                for output_channel_index in range(self.num_out_channel):\n",
    "\n",
    "                    Z_prev_windowed = Z_prev_padded[\n",
    "                        row_start : row_start + self.filter_size,\n",
    "                        col_start : col_start + self.filter_size,\n",
    "                        :\n",
    "                    ]\n",
    "\n",
    "                    conv_step_W = self.W[:, :, :, output_channel_index]\n",
    "                    conv_step_b = self.b[:, :, :, output_channel_index]\n",
    "\n",
    "                    self.output_tensor[row, col, output_channel_index] = Utility.convolve_single_step(Z_prev_windowed, conv_step_W, conv_step_b)\n",
    "\n",
    "        # asserting output shape\n",
    "        assert(self.output_tensor.shape == (self.h_new, self.w_new, self.num_out_channel))\n",
    "\n",
    "        if is_training:\n",
    "            # cache some values\n",
    "            pass\n",
    "\n",
    "        # perform activation element wise in this case\n",
    "        print(f'In forward of Convolution output tensor shape before relu {self.output_tensor.shape}')\n",
    "        self.output_tensor = self.relu_activation.activation_f(self.output_tensor)\n",
    "\n",
    "        # asserting output shape\n",
    "        #assert(self.output_tensor.shape == (self.h_new, self.w_new, self.num_out_channel))\n",
    "        print(f'In forward of CNN output tensor shape after relu {self.output_tensor.shape}')\n",
    "\n",
    "    def forward_batch(self, Z_prev, is_training=True):\n",
    "        \"\"\"\n",
    "        Performs a forward operation of the convolution layer\n",
    "        :param Z_prev: The activation of the previous layer\n",
    "        :param is_training: whether we are in training mode or not\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        batch_size = Z_prev.shape[0]\n",
    "        assert Z_prev.shape == (batch_size, self.h_prev, self.w_prev, self.num_channel_prev)\n",
    "\n",
    "        self.output_tensor = np.zeros((batch_size, self.h_new, self.w_new, self.num_out_channel))\n",
    "        Z_prev = np.array(Z_prev, copy=True)\n",
    "\n",
    "        # create zero padded Z_prev\n",
    "        print(f'Z prev shape:{Z_prev.shape}')\n",
    "        Z_prev_padded = Utility.zero_pad(Z_prev, self.padding_size)\n",
    "\n",
    "        # Apply convolution operation over this zero padded previous activation\n",
    "        for image_index in range(batch_size):\n",
    "            current_Z_prev_padded = Z_prev_padded[image_index] # choosing a single tensor from the batch\n",
    "            for row in range(self.h_new):\n",
    "\n",
    "                row_start = row * self.stride\n",
    "\n",
    "                for col in range(self.w_new):\n",
    "\n",
    "                    col_start = col *  self.stride\n",
    "\n",
    "                    for output_channel_index in range(self.num_out_channel):\n",
    "\n",
    "                        Z_prev_windowed = current_Z_prev_padded[\n",
    "                                        row_start : row_start + self.filter_size,\n",
    "                                        col_start : col_start + self.filter_size,\n",
    "                                        :\n",
    "                                        ]\n",
    "\n",
    "                        conv_step_W = self.W[:, :, :, output_channel_index]\n",
    "                        conv_step_b = self.b[:, :, :, output_channel_index]\n",
    "\n",
    "                        self.output_tensor[image_index, row, col, output_channel_index] = Utility.convolve_single_step(Z_prev_windowed, conv_step_W, conv_step_b)\n",
    "\n",
    "        # asserting output shape\n",
    "        assert(self.output_tensor.shape == (batch_size, self.h_new, self.w_new, self.num_out_channel))\n",
    "        print(self.output_tensor.shape)\n",
    "\n",
    "        if is_training:\n",
    "            # cache some values\n",
    "            pass\n",
    "\n",
    "        # perform activation element wise in this case\n",
    "        #self.output_tensor = self.relu_activation.activation_f(self.output_tensor)\n",
    "\n",
    "    def forward(self, Z_prev):\n",
    "        \"\"\"\n",
    "        Performs a forward operation of the convolution layer\n",
    "        :param Z_prev: The activation of the previous layer\n",
    "        :param is_training: whether we are in training mode or not\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        #print(Z_prev.shape)\n",
    "        batch_size = Z_prev.shape[0]\n",
    "        assert Z_prev.shape == (batch_size, self.h_prev, self.w_prev, self.num_channel_prev)\n",
    "\n",
    "        self.output_tensor = np.zeros((batch_size, self.h_new, self.w_new, self.num_out_channel))\n",
    "\n",
    "        # storing the activation for the bac propagation\n",
    "        self.activation_prev_current_layer_cache = Z_prev\n",
    "\n",
    "        Z_prev = np.array(Z_prev, copy=True)\n",
    "\n",
    "        # create zero padded Z_prev\n",
    "        #print(f'Z prev shape:{Z_prev.shape}')\n",
    "        Z_prev_padded = Utility.zero_pad(Z_prev, self.padding_size)\n",
    "\n",
    "        # Apply convolution operation over this zero padded previous activation\n",
    "        for row in range(self.h_new):\n",
    "\n",
    "            row_start = row * self.stride\n",
    "\n",
    "            for col in range(self.w_new):\n",
    "\n",
    "                col_start = col *  self.stride\n",
    "\n",
    "                for output_channel_index in range(self.num_out_channel):\n",
    "\n",
    "                    Z_prev_windowed = Z_prev_padded[:, row_start : row_start + self.filter_size,\n",
    "                                            col_start : col_start + self.filter_size, :]\n",
    "\n",
    "                    conv_step_W = self.W[:, :, :, output_channel_index]\n",
    "                    conv_step_b = self.b[:, :, :, output_channel_index]\n",
    "\n",
    "                    # print('z shape', Z_prev_windowed.shape)\n",
    "                    # print('w shape', conv_step_W.shape)\n",
    "\n",
    "                    # self.output_tensor[:, row, col, output_channel_index] = np.sum(\n",
    "                    #     Z_prev_windowed * conv_step_W,\n",
    "                    #     axis=(1,2,3)\n",
    "                    # ) + conv_step_b\n",
    "\n",
    "                    self.output_tensor[:, row, col, output_channel_index] = Utility.convolve_single_step_over_batch(\n",
    "                        Z_prev_windowed, conv_step_W, conv_step_b\n",
    "                    )\n",
    "\n",
    "            # asserting output shape\n",
    "            assert(self.output_tensor.shape == (batch_size, self.h_new, self.w_new, self.num_out_channel))\n",
    "            #print('output tensor shape:', self.output_tensor.shape)\n",
    "\n",
    "            if self.training_mode:\n",
    "                # cache some values\n",
    "                pass\n",
    "            # # perform activation element wise in this case\n",
    "            # self.output_tensor = self.relu_activation.activation_f(self.output_tensor)\n",
    "\n",
    "    def forward_(self, Z_prev):\n",
    "        \"\"\"\n",
    "        Performs a forward operation of the convolution layer\n",
    "        :param Z_prev: The activation of the previous layer\n",
    "        :param is_training: whether we are in training mode or not\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        print(Z_prev.shape)\n",
    "        batch_size = Z_prev.shape[0]\n",
    "        assert Z_prev.shape == (batch_size, self.h_prev, self.w_prev, self.num_channel_prev)\n",
    "\n",
    "        self.output_tensor = np.zeros((batch_size, self.h_new, self.w_new, self.num_out_channel))\n",
    "        Z_prev = np.array(Z_prev, copy=True)\n",
    "\n",
    "        # create zero padded Z_prev\n",
    "        #print(f'Z prev shape:{Z_prev.shape}')\n",
    "        Z_prev_padded = Utility.zero_pad(Z_prev, self.padding_size)\n",
    "\n",
    "        # Apply convolution operation over this zero padded previous activation\n",
    "        for row in range(self.h_new):\n",
    "\n",
    "            row_start = row * self.stride\n",
    "\n",
    "            for col in range(self.w_new):\n",
    "\n",
    "                col_start = col *  self.stride\n",
    "\n",
    "                Z_prev_windowed = Z_prev_padded[:,row_start : row_start + self.filter_size,\n",
    "                                  col_start : col_start + self.filter_size,:, np.newaxis]\n",
    "\n",
    "                conv_step_W = self.W[np.newaxis, :, :, :, :]\n",
    "                conv_step_b = self.b[:, :, :, :]\n",
    "\n",
    "                # print('z shape', Z_prev_windowed.shape)\n",
    "                # print('w shape', conv_step_W.shape)\n",
    "\n",
    "                # self.output_tensor[:, row, col, output_channel_index] = np.sum(\n",
    "                #     Z_prev_windowed * conv_step_W,\n",
    "                #     axis=(1,2,3)\n",
    "                # ) + conv_step_b\n",
    "\n",
    "                self.output_tensor[:, row, col, :] = Utility.convolve_single_step_over_batch(\n",
    "                    Z_prev_windowed, conv_step_W, conv_step_b\n",
    "                )\n",
    "\n",
    "            # asserting output shape\n",
    "            assert(self.output_tensor.shape == (batch_size, self.h_new, self.w_new, self.num_out_channel))\n",
    "            #print('output tensor shape:', self.output_tensor.shape)\n",
    "\n",
    "            if self.training_mode:\n",
    "                # cache some values\n",
    "                pass\n",
    "\n",
    "            return self.output_tensor\n",
    "\n",
    "            # # perform activation element wise in this case\n",
    "            # self.output_tensor = self.relu_activation.activation_f(self.output_tensor)\n",
    "\n",
    "    def get_output_tensor(self):\n",
    "        return self.output_tensor\n",
    "\n",
    "    def backward(self, dZ: np.array, learning_rate):\n",
    "        mini_batch_size = dZ.shape[0]\n",
    "\n",
    "        # initialize gradient shape\n",
    "        dActivation_prev, dW, db = self.initialize_gradients(mini_batch_size=mini_batch_size)\n",
    "\n",
    "        # do required padding\n",
    "        activation_prev_padded = Utility.zero_pad(self.activation_prev_current_layer_cache, self.padding_size)\n",
    "        dActivation_prev_padded = Utility.zero_pad(dActivation_prev, self.padding_size)\n",
    "\n",
    "        for row in range(self.h_new):\n",
    "\n",
    "            row_start = row * self.stride\n",
    "\n",
    "            for col in range(self.w_new):\n",
    "\n",
    "                col_start = col * self.stride\n",
    "\n",
    "                for output_channel_index in range(self.num_out_channel):\n",
    "\n",
    "                    # Use the corners to define the slice from a_prev_pad\n",
    "                    activation_slice = activation_prev_padded[:, row_start:row_start + self.filter_size, col_start:col_start + self.filter_size, :]\n",
    "\n",
    "                    # Update gradients for the window and the filter's parameters using the code formulas given above\n",
    "                    dActivation_prev_padded[:, row_start:row_start + self.filter_size, col_start:col_start + self.filter_size, :] += self.W[np.newaxis, :,:,:,output_channel_index] * dZ[: , row:row+1, col:col+1, np.newaxis,  output_channel_index] # done works\n",
    "\n",
    "                    # print('a_slice:', a_slice.shape)\n",
    "                    # print('dZ:', dZ[:, h:h+1, w:w+1, np.newaxis, c].shape)\n",
    "                    # s = a_slice * dZ[:, h:h+1, w:w+1, np.newaxis, c]\n",
    "                    # print('s shape:', s.shape)\n",
    "\n",
    "                    dW[:,:,:,output_channel_index] += np.sum(activation_slice * dZ[:, row:row+1, col:col+1, np.newaxis, output_channel_index], axis=0)\n",
    "\n",
    "                    db[:,:,:,output_channel_index] += np.sum(dZ[:, row:row+1, col:col+1, output_channel_index], axis=(0,1,2))\n",
    "\n",
    "        # unpad the dActivation_padded\n",
    "        if self.padding_size != 0:\n",
    "            dActivation_prev[:, :, :, :] = dActivation_prev_padded[:,\n",
    "                                       self.padding_size:-self.padding_size,\n",
    "                                       self.padding_size:-self.padding_size,\n",
    "                                       :]\n",
    "        else:\n",
    "            dActivation_prev = dActivation_prev_padded\n",
    "\n",
    "        # careful here!!!\n",
    "        dW = dW / mini_batch_size\n",
    "        db = db / mini_batch_size\n",
    "\n",
    "        assert dActivation_prev.shape == (mini_batch_size, self.h_prev, self.w_prev, self.num_channel_prev)\n",
    "\n",
    "        assert dW.shape == (self.filter_size, self.filter_size, self.num_channel_prev, self.num_out_channel)\n",
    "\n",
    "        assert db.shape == (1,1,1,self.num_out_channel)\n",
    "\n",
    "        self.update_CNN_parameters(dW, db, learning_rate=learning_rate)\n",
    "\n",
    "        #print('output of cnn backward:', dActivation_prev)\n",
    "        #print('shape of output cnn backward: ', dActivation_prev.shape)\n",
    "        return dActivation_prev\n",
    "\n",
    "    def initialize_gradients(self, mini_batch_size):\n",
    "        dActivation_prev = np.zeros((mini_batch_size, self.h_prev, self.w_prev, self.num_channel_prev))\n",
    "\n",
    "        dW = np.zeros((self.filter_size, self.filter_size, self.num_channel_prev, self.num_out_channel))\n",
    "\n",
    "        db = np.zeros((1,1,1, self.num_out_channel))\n",
    "\n",
    "        return dActivation_prev, dW, db\n",
    "\n",
    "    def update_CNN_parameters(self, dW : np.array, db: np.array, learning_rate: float):\n",
    "        #print(f'learning rate: {learning_rate}')\n",
    "        self.W = self.W - learning_rate * dW\n",
    "        self.b = self.b - learning_rate * db\n",
    "\n",
    "        # print('------------------ccccccccccccccccccccc----------------------------')\n",
    "        # print(f'layer {self.layer_name} W updated: {self.W}')\n",
    "        # print(f'layer {self.layer_name} b updated: {self.b}')\n",
    "\n",
    "        f = open(self.file_name, 'a+')\n",
    "\n",
    "        f.write(f'W of {self.layer_name} layer: \\n')\n",
    "        f.write(str(self.W))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "        f.write(f'b of {self.layer_name} layer: \\n')\n",
    "        f.write(str(self.b))\n",
    "        f.write('\\n')\n",
    "\n",
    "        f.close()\n",
    "\n",
    "\n",
    "    def print_layer_dimensions(self):\n",
    "        print(f'Output Tensor Dimensions: {self.output_tensor.shape}')\n",
    "        print(f'Weight Dimension: {self.W.shape}')\n",
    "        print(f'Bias Dimension: {self.b.shape}')\n",
    "\n",
    "    def get_output_dimension(self) -> Tuple:\n",
    "        return self.h_new, self.w_new, self.num_out_channel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    # class variable\n",
    "    layer_num = 1\n",
    "\n",
    "    def __init__(self):\n",
    "        self.input_dim = None\n",
    "        self.output_tensor = None\n",
    "        self.output_dim = None\n",
    "        self.h_prev, self.w_prev, self.num_channel_prev = None, None, None\n",
    "        self.layer_name = 'Flatten__' + str(self.layer_num)\n",
    "        self.__class__.layer_num += 1\n",
    "        self.is_trainable = False\n",
    "        self.shape_input_tensor = None\n",
    "\n",
    "    def initialize_flatten_layer_dimensions(self, prev_layer_output_dim):\n",
    "        \"\"\"\n",
    "        :param prev_layer_output_dim: prev layer output of shape (new_h, new_w, new_channel)\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        self.h_prev, self.w_prev, self.num_channel_prev  = prev_layer_output_dim\n",
    "        self.output_dim = self.h_prev * self.w_prev * self.num_channel_prev\n",
    "\n",
    "    def forward(self, Z_prev: np.array) -> np.array:\n",
    "        \"\"\"\n",
    "\n",
    "        :param Z_prev: Z_prev of shape (1/batch size, prev_h, prev_w, prev_color_channel)\n",
    "        :return: tensor of shape (1/batch size, prev_h * prev_w * prev_color_channel)\n",
    "        \"\"\"\n",
    "\n",
    "        self.shape_input_tensor = Z_prev.shape\n",
    "        self.output_tensor = Z_prev.reshape(Z_prev.shape[0], Z_prev.shape[1] * Z_prev.shape[2] * Z_prev.shape[3])\n",
    "\n",
    "        assert self.output_tensor.shape[1] == self.output_dim\n",
    "\n",
    "    def forward_wob(self, Z_prev: np.array) -> np.array:\n",
    "        self.output_tensor = Z_prev.reshape(1, Z_prev.shape[0] * Z_prev.shape[1] * Z_prev.shape[2])\n",
    "\n",
    "    def get_output_dimension(self):\n",
    "        return self.output_dim\n",
    "\n",
    "    def get_output_tensor(self) -> np.array:\n",
    "        return self.output_tensor\n",
    "\n",
    "    def backward(self, dZ: np.array):\n",
    "        \"\"\"\n",
    "\n",
    "        :param dZ: dZ shape: (batch size/1, prev_h * prev_w * prev_color_channel)\n",
    "        :return: tensor of shape: (batch size/1, prev_h, prev_w, prev_color_channel\n",
    "        \"\"\"\n",
    "\n",
    "        assert dZ.shape == self.output_tensor.shape\n",
    "\n",
    "        dZ_reshaped = dZ.reshape(self.shape_input_tensor)\n",
    "\n",
    "        return dZ_reshaped\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MaxPool"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class MaxPool:\n",
    "    # class variable\n",
    "    layer_num = 1\n",
    "\n",
    "    def __init__(self, filter_size, stride):\n",
    "        self.filter_size = filter_size\n",
    "        self.stride = stride\n",
    "        self.h_prev, self.w_prev, self.num_channel_prev = None, None, None\n",
    "        self.h_new, self.w_new, self.num_out_channel = None, None, None\n",
    "        self.output_tensor = None\n",
    "        self.cache = {}\n",
    "        self.layer_name = 'MaxPool__'+ str(self.layer_num)\n",
    "        self.__class__.layer_num += 1\n",
    "        self.is_trainable = False\n",
    "        self.training_mode = False\n",
    "        self.activation_prev_cached = None\n",
    "\n",
    "    def toggle_training_mode(self):\n",
    "        if not self.training_mode:\n",
    "            self.training_mode = True\n",
    "        else:\n",
    "            self.training_mode = False\n",
    "\n",
    "    def initialize_max_pool_params(self, prev_layer_output_dim):\n",
    "        \"\"\"\n",
    "        Initializes output dimensions with the dimension of the previous layers\n",
    "        :param prev_layer_output_dim: output dimension of the layer immediately before this layer\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        self.h_prev, self.w_prev , self.num_channel_prev = prev_layer_output_dim\n",
    "        self.h_new = int((self.h_prev - self.filter_size) / self.stride + 1)\n",
    "        self.w_new = int((self.w_prev - self.filter_size) / self.stride + 1)\n",
    "        self.num_out_channel = self.num_channel_prev\n",
    "\n",
    "    def forward_wob(self, Z_prev, is_training):\n",
    "\n",
    "        #print('prev z shape in maxpool:', Z_prev.shape)\n",
    "        assert Z_prev.shape == (self.h_prev, self.w_prev, self.num_channel_prev)\n",
    "        #print('here')\n",
    "        Z_prev = np.array(Z_prev, copy=True)\n",
    "        #print('there')\n",
    "        self.output_tensor = np.zeros((self.h_new, self.w_new, self.num_out_channel))\n",
    "\n",
    "        #print('Going for max pooling')\n",
    "        # Apply convolution operation over this zero padded previous activation\n",
    "        for row in range(self.h_new):\n",
    "\n",
    "            row_start = row * self.stride\n",
    "\n",
    "            for col in range(self.w_new):\n",
    "\n",
    "                col_start = col *  self.stride\n",
    "\n",
    "                for output_channel_index in range(self.num_out_channel):\n",
    "\n",
    "                    Z_prev_windowed = Z_prev[\n",
    "                                      row_start : row_start + self.filter_size,\n",
    "                                      col_start : col_start + self.filter_size,\n",
    "                                      output_channel_index\n",
    "                                      ]\n",
    "\n",
    "                    self.output_tensor[row, col, output_channel_index] = Utility.get_max_pool_window(Z_prev_windowed)\n",
    "\n",
    "        assert self.output_tensor.shape == (self.h_new, self.w_new, self.num_out_channel)\n",
    "        if is_training:\n",
    "            pass\n",
    "        print('Max pool forward done')\n",
    "\n",
    "    def forward(self, Z_prev):\n",
    "\n",
    "        batch_size = Z_prev.shape[0]\n",
    "        assert Z_prev.shape == (batch_size, self.h_prev, self.w_prev, self.num_channel_prev)\n",
    "\n",
    "        self.activation_prev_cached = Z_prev\n",
    "\n",
    "        self.output_tensor = np.zeros((batch_size, self.h_new, self.w_new, self.num_out_channel))\n",
    "        Z_prev = np.array(Z_prev, copy=True)\n",
    "\n",
    "        # Apply convolution operation over this zero padded previous activation\n",
    "        for row in range(self.h_new):\n",
    "\n",
    "            row_start = row * self.stride\n",
    "\n",
    "            for col in range(self.w_new):\n",
    "\n",
    "                col_start = col *  self.stride\n",
    "\n",
    "                for output_channel_index in range(self.num_out_channel):\n",
    "\n",
    "                    Z_prev_windowed = Z_prev[:,\n",
    "                                    row_start : row_start + self.filter_size,\n",
    "                                    col_start : col_start + self.filter_size,\n",
    "                                    output_channel_index\n",
    "                                      ]\n",
    "\n",
    "                    self.output_tensor[:, row, col, output_channel_index] = Utility.get_max_pool_window_over_batch(Z_prev_windowed)\n",
    "\n",
    "        assert self.output_tensor.shape == (batch_size, self.h_new, self.w_new, self.num_out_channel)\n",
    "        if self.training_mode:\n",
    "            pass\n",
    "\n",
    "    def forward_(self, Z_prev):\n",
    "\n",
    "        batch_size = Z_prev.shape[0]\n",
    "        assert Z_prev.shape == (batch_size, self.h_prev, self.w_prev, self.num_channel_prev)\n",
    "        self.activation_prev_cached = Z_prev\n",
    "\n",
    "        self.output_tensor = np.zeros((batch_size, self.h_new, self.w_new, self.num_out_channel))\n",
    "        Z_prev = np.array(Z_prev, copy=True)\n",
    "\n",
    "        # Apply convolution operation over this zero padded previous activation\n",
    "        for row in range(self.h_new):\n",
    "\n",
    "            row_start = row * self.stride\n",
    "\n",
    "            for col in range(self.w_new):\n",
    "\n",
    "                col_start = col *  self.stride\n",
    "\n",
    "\n",
    "                Z_prev_windowed = Z_prev[:,\n",
    "                                    row_start : row_start + self.filter_size,\n",
    "                                    col_start : col_start + self.filter_size,\n",
    "                                      :\n",
    "                                    ]\n",
    "\n",
    "                self.output_tensor[:, row, col, :] = Utility.get_max_pool_window_over_batch(Z_prev_windowed)\n",
    "\n",
    "        assert self.output_tensor.shape == (batch_size, self.h_new, self.w_new, self.num_out_channel)\n",
    "        if self.training_mode:\n",
    "            pass\n",
    "\n",
    "    def print_layer_dimensions(self):\n",
    "        print(f'Output Tensor Dimensions: {self.output_tensor.shape}')\n",
    "\n",
    "    def get_output_tensor(self):\n",
    "        return self.output_tensor\n",
    "\n",
    "    # WOB\n",
    "    def backward_(self, dActivation_pool: np.array):\n",
    "\n",
    "        dActivation_pool_prev = np.zeros_like(self.activation_prev_cached)\n",
    "        print(dActivation_pool_prev.shape)\n",
    "        mini_batch_size = self.activation_prev_cached.shape[0]\n",
    "        print('mini batch size:', mini_batch_size)\n",
    "\n",
    "        for batch_index in range(mini_batch_size):\n",
    "            # first select a fixed tensor from the batch\n",
    "            activation_prev = self.activation_prev_cached[batch_index, :, :, :]\n",
    "\n",
    "            # print('dA shape:', dA.shape)\n",
    "            # print('h:', self.h_new)\n",
    "            # print('w:', self.w_new)\n",
    "            # print('c:', self.num_out_channel)\n",
    "\n",
    "            for row in range(self.h_new):\n",
    "\n",
    "                for col in range(self.w_new):\n",
    "\n",
    "                    for output_channel_index in range(self.num_out_channel):\n",
    "\n",
    "                        row_start = row * self.stride\n",
    "                        row_end = row * self.stride + self.filter_size\n",
    "                        col_start = col * self.stride\n",
    "                        col_end = col * self.stride + self.filter_size\n",
    "\n",
    "                        activation_prev_window = activation_prev[\n",
    "                            row_start: row_end,\n",
    "                            col_start: col_end,\n",
    "                            output_channel_index\n",
    "                        ]\n",
    "\n",
    "                        # print('before the mask:', activation_prev_window)\n",
    "                        mask = Utility.get_mask_from_tensor(activation_prev_window)\n",
    "                        # print('the mashk:', mask)\n",
    "                        # print(dActivation_pool.shape)\n",
    "                        # print('batch index: ', batch_index)\n",
    "                        # print('row: ', row)\n",
    "                        # print('col: ', col)\n",
    "                        # print('output channel index: ', output_channel_index)\n",
    "                        # s = dActivation_pool[batch_index, row, col, output_channel_index]\n",
    "                        dActivation_pool_prev[batch_index, row_start: row_end, col_start : col_end,output_channel_index] +=  dActivation_pool[batch_index, row, col, output_channel_index] * mask\n",
    "\n",
    "                        #print(f'for batch {batch_index} {dActivation_pool_prev[batch_index,row: row + self.filter_size,col: col + self.filter_size,output_channel_index]}')\n",
    "\n",
    "        # print(dActivation_pool.shape)\n",
    "        #print(self.activation_prev_cached.shape)\n",
    "        assert dActivation_pool_prev.shape == self.activation_prev_cached.shape\n",
    "        print('-----------------------------------------------------------------------')\n",
    "        print('Output of backward pooling non batched: ', dActivation_pool_prev)\n",
    "        return dActivation_pool_prev\n",
    "\n",
    "    # With Batching\n",
    "    def backward(self, dActivation_pool: np.array):\n",
    "\n",
    "        last_mask = None\n",
    "        last_dA = None\n",
    "\n",
    "        # print('sssssssssssssssssssssssssssssssssssssssssssss')\n",
    "        # print('dA from previous:', dActivation_pool)\n",
    "        # print()\n",
    "\n",
    "        dActivation_pool_prev = np.zeros_like(self.activation_prev_cached)\n",
    "        #print(self.activation_prev_cached.shape)\n",
    "        mini_batch_size = self.activation_prev_cached.shape[0]\n",
    "        #print('mini batch size:', mini_batch_size)\n",
    "\n",
    "        for row in range(self.h_new):\n",
    "            row_start = row * self.stride\n",
    "            for col in range(self.w_new):\n",
    "                col_start = col * self.stride\n",
    "                for output_channel_index in range(self.num_out_channel):\n",
    "\n",
    "\n",
    "                    activation_prev_window = self.activation_prev_cached[:, row_start: row_start + self.filter_size, col_start: col_start + self.filter_size, output_channel_index]\n",
    "                    #print('before the mask:', activation_prev_window)\n",
    "                    mask = Utility.get_mask_from_tensor_batch(activation_prev_window)\n",
    "                    # last_mask = mask\n",
    "                    # last_dA = dActivation_pool[:,  row: row + 1,  col: col + 1, output_channel_index]\n",
    "\n",
    "                    dActivation_pool_prev[:, row_start: row_start + self.filter_size, col_start: col_start + self.filter_size, output_channel_index] += dActivation_pool[:,  row: row + 1,  col: col + 1, output_channel_index] * mask\n",
    "\n",
    "\n",
    "        assert dActivation_pool_prev.shape == self.activation_prev_cached.shape\n",
    "        # print('xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx')\n",
    "        # print('mask shape:', last_mask.shape)\n",
    "        # print('the mask:', last_mask)\n",
    "        #\n",
    "        # print('the dA:', last_dA)\n",
    "        # print('------------------------------------------------')\n",
    "        # print('In pooling output custom:  -- dA', dActivation_pool_prev)\n",
    "        return dActivation_pool_prev\n",
    "\n",
    "    def get_output_dimension(self):\n",
    "        return self.h_new, self.w_new, self.num_out_channel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Denselayer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class DenseLayer:\n",
    "\n",
    "    # class variable\n",
    "    layer_num = 1\n",
    "    file_name = './weights.txt'\n",
    "\n",
    "    def __init__(self, num_units):\n",
    "        self.W = None\n",
    "        self.b = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "        self.num_units = num_units\n",
    "        self.A_prev_layer_cached = None\n",
    "        self.output_tensor = None\n",
    "        self.layer_name = 'Dense__' + str(self.__class__.layer_num)\n",
    "        self.__class__.layer_num += 1\n",
    "        self.is_trainable = True\n",
    "        self.training_mode = False\n",
    "\n",
    "    def toggle_training_mode(self):\n",
    "        if not self.training_mode:\n",
    "            self.training_mode = True\n",
    "        else:\n",
    "            self.training_mode = False\n",
    "\n",
    "\n",
    "    def initialize_dense_layer_weights_biases(self, prev_layer_output_dim):\n",
    "        self.W = np.random.randn(self.num_units, prev_layer_output_dim) * np.sqrt(2/prev_layer_output_dim)\n",
    "        self.b = np.zeros((self.num_units, 1)) # will be broadcast to (hidden_units, batch_size) before addition\n",
    "\n",
    "        #print('W dense: ', self.W)\n",
    "\n",
    "    def forward(self, A_prev_layer):\n",
    "        \"\"\"\n",
    "        :param A_prev_layer: tensor of shape (batch, prev_flattened_shape)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        # print('starting of dense: ', A_prev_layer)\n",
    "        # print(f'A_prev_layer shape: {A_prev_layer.shape}')\n",
    "        assert A_prev_layer.shape[1] == self.W.shape[1]\n",
    "\n",
    "        self.A_prev_layer_cached = A_prev_layer\n",
    "\n",
    "        A_prev_layer = np.array(A_prev_layer, copy=True)\n",
    "        A_prev_layer_reshaped = A_prev_layer.T\n",
    "\n",
    "        Z = np.dot(self.W, A_prev_layer_reshaped) + self.b\n",
    "\n",
    "        self.output_tensor = Z.T # converting to (batch_size, num_units)\n",
    "        #print('dense layer output: ',Z)\n",
    "\n",
    "        # assert the output tensor shape should be (num_hidden_units, batch size)\n",
    "        assert self.output_tensor.shape == (A_prev_layer_reshaped.shape[1], self.num_units)\n",
    "\n",
    "        if self.training_mode:\n",
    "            pass\n",
    "\n",
    "    def get_output_tensor(self):\n",
    "        return self.output_tensor\n",
    "\n",
    "    def backward(self, dZ : np.array, learning_rate):\n",
    "        \"\"\"\n",
    "\n",
    "        :param dZ: the gradient of loss with respect to this layers output Z. dZ = dL/dZ. Shape: (batch size , num_units)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        #\n",
    "        # print('Start of dense backward: ', dZ)\n",
    "        #print(learning_rate)\n",
    "\n",
    "        # for softmax activation after this, the value of dZ = y_pred - y\n",
    "        A_prev_layer = self.A_prev_layer_cached\n",
    "        mini_batch_size = dZ.shape[0]\n",
    "        dW = (1/mini_batch_size) * np.dot(dZ.T, A_prev_layer) # (num unit, 1) * (1, x) --> (num unit, x)\n",
    "        db = (1/mini_batch_size) * np.sum(dZ.T, axis=1, keepdims=True)\n",
    "        #dW =  np.dot(dZ.T, A_prev_layer) # (num unit, 1) * (1, x) --> (num unit, x)\n",
    "        dA_prev_layer = np.dot(dZ, self.W)\n",
    "        #db = np.sum(dZ.T, axis=1, keepdims=True)\n",
    "\n",
    "        # print('dW', dW)\n",
    "        # print('dB', db)\n",
    "\n",
    "        #print(dW.shape)\n",
    "        #print(db.shape)\n",
    "        #print(self.b.shape)\n",
    "        assert dW.shape == self.W.shape\n",
    "        assert db.shape == self.b.shape\n",
    "        assert dA_prev_layer.shape == A_prev_layer.shape\n",
    "\n",
    "        self.update_parameters(dW, db, learning_rate=learning_rate)\n",
    "        return dA_prev_layer\n",
    "\n",
    "    def get_output_dimension(self):\n",
    "        return self.num_units\n",
    "\n",
    "    def print_layer_dimensions(self):\n",
    "        print(f'Output Tensor Dimensions: {self.output_tensor.shape}')\n",
    "        print(f'Weight Dimension: {self.W.shape}')\n",
    "        print(f'Bias Dimension: {self.b.shape}')\n",
    "\n",
    "    def update_parameters(self, dW: np.array, db: np.array, learning_rate: float):\n",
    "        #print('updating parameters', learning_rate)\n",
    "        self.W = self.W -   (dW * learning_rate)\n",
    "        self.b = self.b -   (db * learning_rate)\n",
    "\n",
    "        #print(f'Weight of {self.layer_name} : {self.W}')\n",
    "        #print(f'Bias of {self.layer_name} : {self.b}')\n",
    "\n",
    "        f = open(self.file_name, 'w+')\n",
    "\n",
    "        f.write(f'W of {self.layer_name} layer: \\n')\n",
    "        f.write(str(self.W))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "        f.write(f'b of {self.layer_name} layer: \\n')\n",
    "        f.write(str(self.b))\n",
    "        f.write('\\n')\n",
    "\n",
    "        f.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Utility"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "class Utility:\n",
    "\n",
    "    @staticmethod\n",
    "    def one_hot_encode(y_true):\n",
    "        # Define the One-hot Encoder\n",
    "        ohe = preprocessing.OneHotEncoder()\n",
    "        ohe.fit(y_true)\n",
    "        y_true = ohe.transform(y_true).toarray()\n",
    "        return y_true\n",
    "\n",
    "    @staticmethod\n",
    "    def zero_pad(tensor, pad_size):\n",
    "        \"\"\"\n",
    "        :param tensor: tensor of shape (batch_size, h, w, num_channel)\n",
    "        :return: padded tensor of shape (h + 2 * pad_size, w + 2 * pad_size, num_channel)\n",
    "        \"\"\"\n",
    "        return np.pad(tensor, ((0,0), (pad_size, pad_size), (pad_size, pad_size), (0,0)), mode='constant', constant_values=0)\n",
    "\n",
    "    @staticmethod\n",
    "    def zero_pad_without_batch(tensor, pad_size):\n",
    "        \"\"\"\n",
    "        :param tensor: tensor of shape (h, w, num_channel)\n",
    "        :return: padded tensor of shape (h + 2 * pad_size, w + 2 * pad_size, num_channel)\n",
    "        \"\"\"\n",
    "        return np.pad(tensor, ((pad_size, pad_size), (pad_size, pad_size), (0,0)), mode='constant', constant_values=0)\n",
    "\n",
    "    @staticmethod\n",
    "    def convolve_single_step(Z_prev_windowed, W, b):\n",
    "        \"\"\"\n",
    "        :param Z_prev_windowed: window of shape (F, F, num_channel_Z_prev)\n",
    "        :param W: kernel/filter/weight of shape (F, F, num_channel_Z_prev)\n",
    "        :param b: bias term of shape (1, 1, 1)\n",
    "        :return: scaler convolved value\n",
    "        \"\"\"\n",
    "        return np.multiply(Z_prev_windowed, W).sum() + float(b)\n",
    "\n",
    "    @staticmethod\n",
    "    def convolve_single_step_over_batch(tensor, W, b):\n",
    "        # print('slice shape:', tensor.shape)\n",
    "        # print('W shape:', W.shape)\n",
    "        # print('b shape:', b.shape)\n",
    "        return np.sum(tensor * W, axis=(1,2,3)) + b\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def get_max_pool_window(Z_prev_windowed):\n",
    "        return Z_prev_windowed.max()\n",
    "\n",
    "    @staticmethod\n",
    "    def get_max_pool_window_over_batch(Z_prev_windowed: np.array):\n",
    "        #print('In max pool', Z_prev_windowed.shape)\n",
    "        #print(np.max(Z_prev_windowed, axis=(1,2)))\n",
    "        return np.max(Z_prev_windowed, axis=(1,2))\n",
    "\n",
    "    @staticmethod\n",
    "    def create_mini_batches(X: np.array, Y: np.array, mini_batch_size: int):\n",
    "        total_data = X.shape[0]\n",
    "        for index in range(0, total_data, mini_batch_size):\n",
    "            start_index = index\n",
    "            end_index = min(start_index + mini_batch_size, total_data)\n",
    "            yield X[start_index: end_index,...], Y[start_index: end_index, ...]\n",
    "\n",
    "    @staticmethod\n",
    "    def get_mask_from_tensor(tensor: np.array):\n",
    "        mask = (tensor == np.max(tensor))\n",
    "        return mask\n",
    "\n",
    "    @staticmethod\n",
    "    def get_mask_from_tensor_batch(tensor: np.array):\n",
    "        mask = (tensor == tensor.max(axis=(1,2)).reshape(tensor.shape[0], 1, 1))\n",
    "        return mask\n",
    "\n",
    "    @staticmethod\n",
    "    def read_model_config(file_path, data_loader):\n",
    "\n",
    "        with open(file_path) as f:\n",
    "            file_lines = [line.strip() for line in f.readlines()]\n",
    "            print(file_lines)\n",
    "\n",
    "            first_dense_layer_index = -1\n",
    "            for index in range(len(file_lines)):\n",
    "                if file_lines[index].startswith(\"FC\") and not file_lines[index - 1].startswith(\"Flatten\"):\n",
    "                    first_dense_layer_index = index\n",
    "                    break\n",
    "\n",
    "            # print(first_dense_layer_index)\n",
    "\n",
    "            if first_dense_layer_index != -1:\n",
    "                file_lines.insert(first_dense_layer_index, 'Flatten')\n",
    "\n",
    "            # print(file_lines)\n",
    "\n",
    "            layer_list = [InputLayer(input_dimension=(data_loader.size, data_loader.size, data_loader.color_channel), is_trainable=False, layer_name='Input')]\n",
    "\n",
    "\n",
    "            for line in file_lines:\n",
    "                if line.startswith(\"Conv\"):\n",
    "                    line_splitted = line.split()\n",
    "                    layer_list.append( Convolution2D(num_out_channel=int(line_splitted[1]), filter_size=int(line_splitted[2]), stride=int(line_splitted[3]), padding_size=int(line_splitted[4])))\n",
    "                elif line.startswith(\"ReLU\"):\n",
    "                    layer_list.append(ReLUActivation())\n",
    "                elif line.startswith(\"Pool\"):\n",
    "                    line_splitted = line.split()\n",
    "                    layer_list.append(MaxPool(filter_size=int(line_splitted[1]), stride=int(line_splitted[2])))\n",
    "                elif line.startswith(\"Flatten\"):\n",
    "                    layer_list.append(Flatten())\n",
    "                elif line.startswith(\"FC\"):\n",
    "                    line_splitted = line.split()\n",
    "                    layer_list.append(DenseLayer(int(line_splitted[1])))\n",
    "                elif line.startswith(\"Softmax\"):\n",
    "                    layer_list.append(SoftmaxActivation())\n",
    "\n",
    "            return layer_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # layer_list=[\n",
    "            #     InputLayer(input_dimension=(mnist.size, mnist.size, mnist.color_channel), is_trainable=False, layer_name='Input'),\n",
    "            #     Convolution2D(num_out_channel=6, filter_size=5, stride=1, padding_size=2),\n",
    "            #     ReLUActivation(),\n",
    "            #     MaxPool(filter_size=2, stride=2),\n",
    "            #     Convolution2D(num_out_channel=12, filter_size=5, stride=1, padding_size=0),\n",
    "            #     ReLUActivation(),\n",
    "            #     MaxPool(filter_size=2, stride=2),\n",
    "            #     Convolution2D(num_out_channel=100, filter_size=5, stride=1, padding_size=0),\n",
    "            #     ReLUActivation(),\n",
    "            #     Flatten(),\n",
    "            #     DenseLayer(10),\n",
    "            #     SoftmaxActivation()\n",
    "            # ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ReLU"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class ReLUActivation:\n",
    "\n",
    "    # class variable\n",
    "    layer_num = 1\n",
    "    def __init__(self):\n",
    "        self.layer_name = 'ReLU__' + str(self.layer_num)\n",
    "        self.__class__.layer_num += 1\n",
    "        self.input_tensor_dimension = None\n",
    "        self.output_tensor = None\n",
    "        self.is_trainable = False\n",
    "        self.input_tensor_cached = None\n",
    "\n",
    "    def set_input_tensor_dimension(self, prev_layer_tensor_dimension):\n",
    "        self.input_tensor_dimension = prev_layer_tensor_dimension\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        #print('Relu Input Tensor Shape: ', tensor.shape)\n",
    "        # print('in relu:', tensor)\n",
    "        # print('After: ', np.maximum(tensor, 0))\n",
    "        self.input_tensor_cached = tensor\n",
    "        self.output_tensor = np.maximum(tensor, 0)\n",
    "\n",
    "    def get_output_dimension(self):\n",
    "        return self.input_tensor_dimension\n",
    "\n",
    "\n",
    "    def backward(self, dA: np.array):\n",
    "        dA = np.array(dA, copy=True)\n",
    "        dA[self.input_tensor_cached <= 0] = 0\n",
    "\n",
    "        # print('In relu: dA', dA)\n",
    "        return dA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "@dataclass(unsafe_hash=True)\n",
    "class InputLayer:\n",
    "    \"\"\"\n",
    "    Class for saving input dimension\n",
    "    \"\"\"\n",
    "    input_dimension: np.array\n",
    "    is_trainable: bool\n",
    "    layer_name: str"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Softmax"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class SoftmaxActivation:\n",
    "\n",
    "    # class variable\n",
    "    layer_num = 1\n",
    "    def __init__(self):\n",
    "        self.input_tensor_dimension = None\n",
    "        self.layer_name = 'Softmax__' + str(self.layer_num)\n",
    "        self.__class__.layer_num += 1\n",
    "        self.output_tensor = None\n",
    "        self.is_trainable = False\n",
    "\n",
    "    def set_input_tensor_dimension(self, prev_layer_tensor_dimension):\n",
    "        self.input_tensor_dimension = prev_layer_tensor_dimension\n",
    "\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        #print('softmax tensor shape:', tensor.shape) # expected tensor shape: (1/batch-size, classes)\n",
    "        exponent = np.exp(tensor - np.max(tensor, axis=1, keepdims=True))\n",
    "\n",
    "        #print('softmax exp shape',exponent.shape)\n",
    "        summation_along_batch = np.sum(exponent, axis=1, keepdims=True)\n",
    "\n",
    "        #print('softmax sum shape:', summation_along_batch.shape)\n",
    "\n",
    "        self.output_tensor = exponent/summation_along_batch\n",
    "\n",
    "        return self.output_tensor\n",
    "\n",
    "\n",
    "    def get_output_dimension(self):\n",
    "        return self.input_tensor_dimension\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(dA: np.array):\n",
    "        \"\"\" passes the backward gradient\n",
    "        :param dA: the gradient wrt to the activation softmax\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return dA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class CrossEntropyLoss:\n",
    "    epsilon = 1e-50\n",
    "\n",
    "    def compute_cost(self, y_pred, y):\n",
    "        mini_batch_size = y.shape[0]\n",
    "        clipped_y_pred = np.clip(y_pred, self.epsilon, 1.0)\n",
    "        cross_entropy_loss = -(1/mini_batch_size) * np.sum(np.multiply(y, np.log(clipped_y_pred)))\n",
    "        return cross_entropy_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Class"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.layers = None # a list of layer object according to input\n",
    "        self.layer_w_gradients = dict() # {'layer name': dw}\n",
    "        self.layer_b_gradients = dict() # {'layer name': db}\n",
    "        self.epochs = None\n",
    "        self.cost_function = None\n",
    "        self.history = {\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'validation_loss': [],\n",
    "            'validation_acc': []\n",
    "        }\n",
    "\n",
    "    def add(self, layer_list):\n",
    "        self.layers = layer_list\n",
    "\n",
    "    def initializer_layer_params(self):\n",
    "        \"\"\"\n",
    "        This method initializes the layers in the model providing the input dimension that the layers expect to get\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        #InputLayer(input_dimension=input_dimension, is_trainable=False, layer_name='Input')\n",
    "\n",
    "        assert self.layers[0].layer_name == 'Input'\n",
    "\n",
    "        for previous_layer, current_layer in zip(self.layers, self.layers[1:]):\n",
    "            prev_output_dim = None\n",
    "            if previous_layer.layer_name == 'Input':\n",
    "                prev_output_dim = previous_layer.input_dimension # H, W, Color Channel\n",
    "            else:\n",
    "                prev_output_dim = previous_layer.get_output_dimension()\n",
    "\n",
    "\n",
    "            if current_layer.layer_name.startswith('Conv2D__'):\n",
    "                current_layer.initialize_output_dimensions(prev_output_dim) # H, W, Color Channel\n",
    "                current_layer.initialize_weights_biases()\n",
    "            elif current_layer.layer_name.startswith('MaxPool__'):\n",
    "                print(prev_output_dim)\n",
    "                current_layer.initialize_max_pool_params(prev_output_dim) # H, W, Color Channel\n",
    "            elif current_layer.layer_name.startswith('Dense__'):\n",
    "                current_layer.initialize_dense_layer_weights_biases(prev_output_dim) # flatten layer dimension\n",
    "            elif current_layer.layer_name.startswith('Flatten__'):\n",
    "                current_layer.initialize_flatten_layer_dimensions(prev_output_dim) # (new_h, new_w, new_channel)\n",
    "            elif current_layer.layer_name.startswith(\"ReLU\") or current_layer.layer_name.startswith(\"Softmax\") :\n",
    "                current_layer.set_input_tensor_dimension(prev_output_dim) # for the activation layers\n",
    "\n",
    "\n",
    "    def compile(self, cost_function):\n",
    "        self.cost_function = cost_function\n",
    "\n",
    "    def train(self, training_data, test_data, epochs=5, learning_rate=0.001, mini_batch_size=32):\n",
    "\n",
    "        self.epochs = epochs\n",
    "        X_test, Y_test = test_data\n",
    "        # Split data into 50% train and 50% test subsets\n",
    "        X_validation, X_test, Y_validation, Y_test = train_test_split(\n",
    "            X_test, Y_test, test_size=0.5, shuffle=False, random_state=1\n",
    "        )\n",
    "        # print(X_validation.shape)\n",
    "        # print(Y_validation.shape)\n",
    "        # print(Y_validation[0:5])\n",
    "\n",
    "        for e in range(epochs):\n",
    "            # each epoch will run through a training once and update weights\n",
    "            print(f'Running Epoch: {e+1}')\n",
    "            X_train, Y_train = training_data\n",
    "            total_data = X_train.shape[0]\n",
    "            num_of_mini_batches = total_data//mini_batch_size\n",
    "\n",
    "\n",
    "            # first we create the mini batches and then run training step through it\n",
    "            i = 1\n",
    "            batch_correct = 0\n",
    "            train_loss = 0\n",
    "            for X, Y in Utility.create_mini_batches(X=X_train, Y=Y_train, mini_batch_size=mini_batch_size):\n",
    "                \"\"\"\n",
    "                X shape --> (mini_batch_size, h, w, color_channel)\n",
    "                Y shape --> (mini_batch_size, num_of_class) (one hot encoded vector)\n",
    "                \"\"\"\n",
    "                Y_pred = self.forward_propagation(X)\n",
    "                # print('final input shape', Y_pred.shape)\n",
    "                # print('final output:', Y_pred)\n",
    "                y_pred_one_hot_encoded = Y_pred == Y_pred.max(axis=1).reshape(Y_pred.shape[0], 1)\n",
    "\n",
    "                #print('Y_pred shape: {}')\n",
    "                #print(metrics.classification_report(Y.argmax(axis=1), y_pred_one_hot_encoded.argmax(axis=1)))\n",
    "                # batch_correct = np.sum(Y.argmax(axis=1) == y_pred_one_hot_encoded.argmax(axis=1))\n",
    "                # batch_acc = batch_correct / mini_batch_size\n",
    "                # print(f'Batch correct: {batch_correct} out of {mini_batch_size}')\n",
    "                # print(f'Batch Acc: {batch_acc * 100} %')\n",
    "                self.backward_propagation(Y_pred,Y, learning_rate, mini_batch_size)\n",
    "                #train_loss = self.cost_function.compute_cost(Y_pred, Y)\n",
    "                #print(f'Loss per batch: {train_loss * 100} %')\n",
    "                print(\"\\rProgress {:1.1%}\".format(i / num_of_mini_batches), end=\"\")\n",
    "                i += 1\n",
    "\n",
    "            print()\n",
    "            self.calculate_metrics(X_train=X_train, Y_train=Y_train, X_validation=X_validation, Y_validation=Y_validation, epoch=e)\n",
    "\n",
    "            # Y_train_pred_all = self.forward_propagation(X_train)\n",
    "            # Y_train_pred_all_one_hot_encoded = Y_train_pred_all == Y_train_pred_all.max(axis=1).reshape(Y_train_pred_all.shape[0], 1)\n",
    "            #\n",
    "            # print(metrics.classification_report(Y_train.argmax(axis=1), Y_train_pred_all_one_hot_encoded.argmax(axis=1)))\n",
    "            # print('macro f1 train set: ')\n",
    "            # print(metrics.f1_score(Y_train.argmax(axis=1), Y_train_pred_all_one_hot_encoded.argmax(axis=1), average='macro'))\n",
    "            #\n",
    "            # train_loss = self.cost_function.compute_cost(Y_train_pred_all, Y_train)\n",
    "            # print(f'Train Loss After a Epoch {e+1}: {train_loss * 100} %')\n",
    "            # self.history['train_loss'].append((train_loss * 100))\n",
    "            #\n",
    "            # train_correct = np.sum(Y_train.argmax(axis=1) == Y_train_pred_all_one_hot_encoded.argmax(axis=1))\n",
    "            # train_acc = train_correct / Y_train.shape[0]\n",
    "            # print(f'Train Acc: {train_acc * 100} %')\n",
    "            # self.history['train_acc'].append((train_acc * 100))\n",
    "            #\n",
    "            # # calculate validation accuracy and loss here\n",
    "            # print('--------------Running On validation data-----------------')\n",
    "            # Y_validation_pred = self.forward_propagation(X_validation)\n",
    "            # Y__validation_pred_one_hot_encoded = Y_validation_pred == Y_validation_pred.max(axis=1).reshape(Y_validation_pred.shape[0], 1)\n",
    "            #\n",
    "            # print(metrics.classification_report(Y_validation.argmax(axis=1), Y__validation_pred_one_hot_encoded.argmax(axis=1)))\n",
    "            # print('macro f1 validation set: ')\n",
    "            # print(metrics.f1_score(Y_validation.argmax(axis=1), Y__validation_pred_one_hot_encoded.argmax(axis=1), average='macro'))\n",
    "            #\n",
    "            # validation_loss = self.cost_function.compute_cost(Y_validation_pred, Y_validation)\n",
    "            # print(f'Validation Loss After a Epoch {e+1}: {validation_loss * 100} %')\n",
    "            # self.history['validation_loss'].append((validation_loss * 100))\n",
    "            #\n",
    "            # val_correct = np.sum(Y_validation.argmax(axis=1) == Y__validation_pred_one_hot_encoded.argmax(axis=1))\n",
    "            # val_acc = val_correct / Y_validation.shape[0]\n",
    "            # print(f'Validation Acc: {val_acc * 100} %')\n",
    "            # self.history['validation_acc'].append((val_acc * 100))\n",
    "\n",
    "        print('Finished Training!')\n",
    "\n",
    "        self.predict(X_test, Y_test)\n",
    "\n",
    "    def predict(self, X_test, Y_test):\n",
    "        print('--------------Running On testing data-----------------')\n",
    "        Y_test_pred = self.forward_propagation(X_test)\n",
    "        Y_test_pred_one_hot_encoded = (Y_test_pred == Y_test_pred.max(axis=1).reshape(Y_test_pred.shape[0], 1))\n",
    "\n",
    "        print(metrics.classification_report(Y_test.argmax(axis=1), Y_test_pred_one_hot_encoded.argmax(axis=1)))\n",
    "        print('macro f1 test set: ')\n",
    "        print(metrics.f1_score(Y_test.argmax(axis=1), Y_test_pred_one_hot_encoded.argmax(axis=1), average='macro'))\n",
    "\n",
    "        test_loss = self.cost_function.compute_cost(Y_test_pred, Y_test)\n",
    "        print(f'Train Loss : {test_loss * 100} %')\n",
    "\n",
    "        test_correct = np.sum(Y_test.argmax(axis=1) == Y_test_pred_one_hot_encoded.argmax(axis=1))\n",
    "        test_acc = test_correct / Y_test.shape[0]\n",
    "        print(f'Test Acc: {test_acc * 100} %')\n",
    "\n",
    "\n",
    "    def forward_propagation(self, X_train) -> np.array:\n",
    "        \"\"\"\n",
    "        Performs a forward pass through the network\n",
    "        :param X_train: nd training tensor (batch_size, h, w, color_channel)\n",
    "        :param is_training: whether we are training or not\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # print(f'In forward propagation: {self.layers[1].W}')\n",
    "\n",
    "        input = X_train\n",
    "        for layer in self.layers[1:]:\n",
    "            # skipping the input layer\n",
    "            #print(f'Forward for layer {layer.layer_name}')\n",
    "            if not layer.layer_name.startswith('ReLU') and not layer.layer_name.startswith('Softmax') and not layer.layer_name.startswith('Flatten'):\n",
    "                layer.toggle_training_mode() # toggling training mode for a layer\n",
    "            layer.forward(input)\n",
    "            input = layer.output_tensor # getting the output tensor of the layer to be the input tensor to the next\n",
    "            #print(f'Output of layer {layer.layer_name}\\n: {input}')\n",
    "\n",
    "            if not layer.layer_name.startswith('ReLU') and not layer.layer_name.startswith('Softmax') and not layer.layer_name.startswith('Flatten'):\n",
    "                layer.toggle_training_mode() # turning the training mode off here\n",
    "\n",
    "\n",
    "\n",
    "        return input\n",
    "\n",
    "    def backward_propagation(self, Y_out, Y, learning_rate, mini_batch_size):\n",
    "        #print('here')\n",
    "\n",
    "        # dA = (Y_out - Y) / mini_batch_size\n",
    "        # print(f'In backpropagation: {self.layers[1].W}')\n",
    "        dA = Y_out - Y\n",
    "        #print('yhat - Y', dA)\n",
    "        for layer in reversed(self.layers[1:]):\n",
    "            #print(f'Running backward for layer {layer.layer_name}')\n",
    "            if layer.is_trainable:\n",
    "                dA = layer.backward(dA, learning_rate)\n",
    "            else:\n",
    "                dA = layer.backward(dA)\n",
    "\n",
    "\n",
    "    def plot_metrics(self):\n",
    "        epochs = range(0,self.epochs)\n",
    "        plt.plot(epochs, self.history['train_acc'])\n",
    "        plt.plot(epochs, self.history['validation_acc'])\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'validation'], loc='upper left')\n",
    "        plt.show()\n",
    "        # summarize history for loss\n",
    "        plt.plot(epochs, self.history['train_loss'])\n",
    "        plt.plot(epochs, self.history['validation_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'validation'], loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def calculate_metrics(self, X_train, Y_train, X_validation, Y_validation, epoch):\n",
    "        print('--------------Running On all training data-----------------')\n",
    "        Y_train_pred_all = self.forward_propagation(X_train)\n",
    "        Y_train_pred_all_one_hot_encoded = Y_train_pred_all == Y_train_pred_all.max(axis=1).reshape(Y_train_pred_all.shape[0], 1)\n",
    "\n",
    "        print(metrics.classification_report(Y_train.argmax(axis=1), Y_train_pred_all_one_hot_encoded.argmax(axis=1)))\n",
    "        print('macro f1 train set: ')\n",
    "        print(metrics.f1_score(Y_train.argmax(axis=1), Y_train_pred_all_one_hot_encoded.argmax(axis=1), average='macro'))\n",
    "\n",
    "        train_loss = self.cost_function.compute_cost(Y_train_pred_all, Y_train)\n",
    "        print(f'Train Loss After a Epoch {epoch+1}: {train_loss * 100} %')\n",
    "        self.history['train_loss'].append((train_loss * 100))\n",
    "\n",
    "        train_correct = np.sum(Y_train.argmax(axis=1) == Y_train_pred_all_one_hot_encoded.argmax(axis=1))\n",
    "        train_acc = train_correct / Y_train.shape[0]\n",
    "        print(f'Train Acc: {train_acc * 100} %')\n",
    "        self.history['train_acc'].append((train_acc * 100))\n",
    "\n",
    "        # calculate validation accuracy and loss here\n",
    "        print('--------------Running On validation data-----------------')\n",
    "        Y_validation_pred = self.forward_propagation(X_validation)\n",
    "        Y__validation_pred_one_hot_encoded = Y_validation_pred == Y_validation_pred.max(axis=1).reshape(Y_validation_pred.shape[0], 1)\n",
    "\n",
    "        print(metrics.classification_report(Y_validation.argmax(axis=1), Y__validation_pred_one_hot_encoded.argmax(axis=1)))\n",
    "        print('macro f1 validation set: ')\n",
    "        print(metrics.f1_score(Y_validation.argmax(axis=1), Y__validation_pred_one_hot_encoded.argmax(axis=1), average='macro'))\n",
    "\n",
    "        validation_loss = self.cost_function.compute_cost(Y_validation_pred, Y_validation)\n",
    "        print(f'Validation Loss After a Epoch {epoch+1}: {validation_loss * 100} %')\n",
    "        self.history['validation_loss'].append((validation_loss * 100))\n",
    "\n",
    "        val_correct = np.sum(Y_validation.argmax(axis=1) == Y__validation_pred_one_hot_encoded.argmax(axis=1))\n",
    "        val_acc = val_correct / Y_validation.shape[0]\n",
    "        print(f'Validation Acc: {val_acc * 100} %')\n",
    "        self.history['validation_acc'].append((val_acc * 100))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.62434536 -0.61175641 -0.52817175 -1.07296862  0.86540763 -2.3015387\n",
      "   1.74481176 -0.7612069   0.3190391  -0.24937038]\n",
      " [ 1.46210794 -2.06014071 -0.3224172  -0.38405435  1.13376944 -1.09989127\n",
      "  -0.17242821 -0.87785842  0.04221375  0.58281521]]\n",
      "a_m [1.74481176 1.46210794]\n"
     ]
    },
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets, svm, metrics\n",
    "a = np.random.randn(2,10)\n",
    "print(a)\n",
    "a_m = a.max(axis=1)\n",
    "print('a_m', a_m)\n",
    "a = a == a.max(axis=1).reshape(a.shape[0], 1)\n",
    "v = a.argmax(axis=1)\n",
    "np.sum(v == v)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# np.random.seed(1)\n",
    "# A_prev = np.random.randn(10,5,7,4) # h, w, c of previous layer\n",
    "# cnn = Convolution2D(num_out_channel=8, filter_size=3, stride=2, padding_size=1)\n",
    "# cnn.initialize_output_dimensions((A_prev.shape[1], A_prev.shape[2], A_prev.shape[3]))\n",
    "# cnn.initialize_weights_biases()\n",
    "# #cnn.print_layer_dimensions()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# cnn.forward_(A_prev)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# print(cnn.output_tensor.shape)\n",
    "# print(\"Z'as mean =\\n\", np.mean(cnn.output_tensor))\n",
    "# print(\"Z[3,2,1] =\\n\", cnn.output_tensor[3,2,1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# # Case 1: stride of 1\n",
    "# np.random.seed(1)\n",
    "# A_prev = np.random.randn(2, 5, 5, 3)\n",
    "# maxpool = MaxPool(filter_size=3, stride=1)\n",
    "# maxpool.initialize_max_pool_params((A_prev.shape[1],A_prev.shape[2],A_prev.shape[3]))\n",
    "# maxpool.forward_(A_prev)\n",
    "# maxpool.print_layer_dimensions()\n",
    "# print(maxpool.output_tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "(10000,)\n",
      "(10000,)\n",
      "(10000,)\n",
      "(10000,)\n",
      "(10000,)\n",
      "Shape: (50000, 32, 32, 3)\n",
      "Shape: (50000, 1)\n",
      "Shape: (10000, 32, 32, 3)\n",
      "Shape: (10000, 1)\n",
      "(50000, 32, 32, 3)\n",
      "(50000, 10)\n"
     ]
    }
   ],
   "source": [
    "cifer_dataloader = Cifer10DataLoader('/home/akil/Work/Work/Academics/4-2/ML/Assignment-3/dataset/cifer-10/cifar-10-python/cifar-10-batches-py')\n",
    "cifer_dataloader.concatenate_data()\n",
    "cifer_dataloader.preprocess_data()\n",
    "print(cifer_dataloader.data['train_images'].shape)\n",
    "print(cifer_dataloader.data['train_labels'].shape)\n",
    "# total_train_data = cifer_dataloader.data['train_images'].shape[0]\n",
    "# mini_batch_size = 32\n",
    "# p = np.random.permutation(total_data)\n",
    "# cifer_dataloader.data['train_images'], cifer_dataloader.data['train_labels'] = cifer_dataloader.data['train_images'][p, :], cifer_dataloader.data['train_labels'][p, :]\n",
    "X_train = cifer_dataloader.data['train_images']\n",
    "Y_train = cifer_dataloader.data['train_labels']\n",
    "X_test = cifer_dataloader.data['test_images']\n",
    "Y_test = cifer_dataloader.data['test_labels']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing MNIST lr:0.02 e: 10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000, 10)\n",
      "(10000, 28, 28, 1)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "mnist = MnistDataLoader('./dataset/mnist')\n",
    "mnist.load_mnist()\n",
    "mnist.preprocess_data()\n",
    "\n",
    "X_train = mnist.data[mnist.data_list[0]]\n",
    "Y_train = mnist.data[mnist.data_list[1]]\n",
    "X_test = mnist.data[mnist.data_list[2]]\n",
    "Y_test = mnist.data[mnist.data_list[3]]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Conv 6 5 1 2', 'ReLU', 'Pool 2 2', 'Conv 12 5 1 0', 'ReLU', 'Pool 2 2', 'Conv 100 5 1 0', 'ReLU', 'FC 10', 'Softmax']\n",
      "The layer name:  Conv2D__1 2\n",
      "The layer name:  Conv2D__2 3\n",
      "The layer name:  Conv2D__3 4\n",
      "(28, 28, 6)\n",
      "(10, 10, 12)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "cnn = Model()\n",
    "cnn.add(Utility.read_model_config('./input.txt', mnist))\n",
    "cnn.compile(cost_function=CrossEntropyLoss())\n",
    "cnn.initializer_layer_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Epoch: 1\n",
      "Progress 100.0%\n",
      "--------------Running On all training data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      5923\n",
      "           1       0.96      0.99      0.98      6742\n",
      "           2       0.97      0.94      0.96      5958\n",
      "           3       0.97      0.93      0.95      6131\n",
      "           4       0.95      0.97      0.96      5842\n",
      "           5       0.95      0.97      0.96      5421\n",
      "           6       0.99      0.96      0.97      5918\n",
      "           7       0.98      0.92      0.95      6265\n",
      "           8       0.96      0.93      0.94      5851\n",
      "           9       0.88      0.97      0.92      5949\n",
      "\n",
      "    accuracy                           0.96     60000\n",
      "   macro avg       0.96      0.96      0.96     60000\n",
      "weighted avg       0.96      0.96      0.96     60000\n",
      "\n",
      "macro f1 train set: \n",
      "0.956380239822684\n",
      "Train Loss After a Epoch 1: 13.821344086149576 %\n",
      "Train Acc: 95.65166666666667 %\n",
      "--------------Running On validation data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96       460\n",
      "           1       0.96      0.99      0.98       571\n",
      "           2       0.98      0.94      0.96       530\n",
      "           3       0.95      0.94      0.95       500\n",
      "           4       0.94      0.96      0.95       500\n",
      "           5       0.92      0.97      0.94       456\n",
      "           6       0.99      0.90      0.94       462\n",
      "           7       0.97      0.90      0.93       512\n",
      "           8       0.95      0.91      0.93       489\n",
      "           9       0.89      0.95      0.92       520\n",
      "\n",
      "    accuracy                           0.95      5000\n",
      "   macro avg       0.95      0.95      0.95      5000\n",
      "weighted avg       0.95      0.95      0.95      5000\n",
      "\n",
      "macro f1 validation set: \n",
      "0.9450115137081377\n",
      "Validation Loss After a Epoch 1: 16.99197735721404 %\n",
      "Validation Acc: 94.54 %\n",
      "Running Epoch: 2\n",
      "Progress 100.0%\n",
      "--------------Running On all training data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      5923\n",
      "           1       0.97      0.99      0.98      6742\n",
      "           2       0.97      0.97      0.97      5958\n",
      "           3       0.98      0.95      0.97      6131\n",
      "           4       0.97      0.98      0.98      5842\n",
      "           5       0.94      0.98      0.96      5421\n",
      "           6       1.00      0.96      0.98      5918\n",
      "           7       0.99      0.96      0.97      6265\n",
      "           8       0.97      0.94      0.96      5851\n",
      "           9       0.94      0.98      0.96      5949\n",
      "\n",
      "    accuracy                           0.97     60000\n",
      "   macro avg       0.97      0.97      0.97     60000\n",
      "weighted avg       0.97      0.97      0.97     60000\n",
      "\n",
      "macro f1 train set: \n",
      "0.9702643545201577\n",
      "Train Loss After a Epoch 2: 9.315006426562286 %\n",
      "Train Acc: 97.04833333333333 %\n",
      "--------------Running On validation data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       460\n",
      "           1       0.97      0.99      0.98       571\n",
      "           2       0.97      0.97      0.97       530\n",
      "           3       0.96      0.97      0.97       500\n",
      "           4       0.97      0.97      0.97       500\n",
      "           5       0.92      0.99      0.95       456\n",
      "           6       0.99      0.90      0.95       462\n",
      "           7       0.98      0.94      0.96       512\n",
      "           8       0.98      0.93      0.95       489\n",
      "           9       0.94      0.97      0.95       520\n",
      "\n",
      "    accuracy                           0.96      5000\n",
      "   macro avg       0.96      0.96      0.96      5000\n",
      "weighted avg       0.96      0.96      0.96      5000\n",
      "\n",
      "macro f1 validation set: \n",
      "0.962259038199049\n",
      "Validation Loss After a Epoch 2: 11.929393159802633 %\n",
      "Validation Acc: 96.28 %\n",
      "Running Epoch: 3\n",
      "Progress 100.0%\n",
      "--------------Running On all training data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      5923\n",
      "           1       0.98      0.99      0.99      6742\n",
      "           2       0.98      0.98      0.98      5958\n",
      "           3       0.98      0.96      0.97      6131\n",
      "           4       0.98      0.98      0.98      5842\n",
      "           5       0.94      0.99      0.96      5421\n",
      "           6       1.00      0.95      0.98      5918\n",
      "           7       0.99      0.97      0.98      6265\n",
      "           8       0.98      0.95      0.96      5851\n",
      "           9       0.95      0.98      0.97      5949\n",
      "\n",
      "    accuracy                           0.98     60000\n",
      "   macro avg       0.98      0.98      0.98     60000\n",
      "weighted avg       0.98      0.98      0.98     60000\n",
      "\n",
      "macro f1 train set: \n",
      "0.9751084158377177\n",
      "Train Loss After a Epoch 3: 7.725147342712928 %\n",
      "Train Acc: 97.53500000000001 %\n",
      "--------------Running On validation data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98       460\n",
      "           1       0.97      0.99      0.98       571\n",
      "           2       0.98      0.98      0.98       530\n",
      "           3       0.96      0.97      0.97       500\n",
      "           4       0.98      0.97      0.98       500\n",
      "           5       0.91      0.99      0.95       456\n",
      "           6       1.00      0.90      0.95       462\n",
      "           7       0.99      0.96      0.97       512\n",
      "           8       0.99      0.95      0.97       489\n",
      "           9       0.95      0.97      0.96       520\n",
      "\n",
      "    accuracy                           0.97      5000\n",
      "   macro avg       0.97      0.97      0.97      5000\n",
      "weighted avg       0.97      0.97      0.97      5000\n",
      "\n",
      "macro f1 validation set: \n",
      "0.9674683333958057\n",
      "Validation Loss After a Epoch 3: 10.660107387283386 %\n",
      "Validation Acc: 96.8 %\n",
      "Running Epoch: 4\n",
      "Progress 100.0%\n",
      "--------------Running On all training data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5923\n",
      "           1       0.98      1.00      0.99      6742\n",
      "           2       0.99      0.98      0.98      5958\n",
      "           3       0.98      0.97      0.98      6131\n",
      "           4       0.98      0.99      0.99      5842\n",
      "           5       0.94      0.99      0.96      5421\n",
      "           6       1.00      0.95      0.97      5918\n",
      "           7       0.99      0.98      0.98      6265\n",
      "           8       0.98      0.96      0.97      5851\n",
      "           9       0.96      0.98      0.97      5949\n",
      "\n",
      "    accuracy                           0.98     60000\n",
      "   macro avg       0.98      0.98      0.98     60000\n",
      "weighted avg       0.98      0.98      0.98     60000\n",
      "\n",
      "macro f1 train set: \n",
      "0.9774641320323697\n",
      "Train Loss After a Epoch 4: 6.961234340697936 %\n",
      "Train Acc: 97.77 %\n",
      "--------------Running On validation data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98       460\n",
      "           1       0.97      1.00      0.98       571\n",
      "           2       0.98      0.98      0.98       530\n",
      "           3       0.97      0.97      0.97       500\n",
      "           4       0.99      0.98      0.98       500\n",
      "           5       0.91      1.00      0.95       456\n",
      "           6       1.00      0.89      0.94       462\n",
      "           7       0.98      0.96      0.97       512\n",
      "           8       0.99      0.95      0.97       489\n",
      "           9       0.96      0.97      0.96       520\n",
      "\n",
      "    accuracy                           0.97      5000\n",
      "   macro avg       0.97      0.97      0.97      5000\n",
      "weighted avg       0.97      0.97      0.97      5000\n",
      "\n",
      "macro f1 validation set: \n",
      "0.9688023344671445\n",
      "Validation Loss After a Epoch 4: 9.996909137051256 %\n",
      "Validation Acc: 96.94 %\n",
      "Running Epoch: 5\n",
      "Progress 100.0%\n",
      "--------------Running On all training data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5923\n",
      "           1       0.97      1.00      0.98      6742\n",
      "           2       0.99      0.98      0.98      5958\n",
      "           3       0.99      0.97      0.98      6131\n",
      "           4       0.99      0.99      0.99      5842\n",
      "           5       0.95      0.99      0.97      5421\n",
      "           6       1.00      0.96      0.98      5918\n",
      "           7       0.99      0.98      0.99      6265\n",
      "           8       0.98      0.96      0.97      5851\n",
      "           9       0.97      0.99      0.98      5949\n",
      "\n",
      "    accuracy                           0.98     60000\n",
      "   macro avg       0.98      0.98      0.98     60000\n",
      "weighted avg       0.98      0.98      0.98     60000\n",
      "\n",
      "macro f1 train set: \n",
      "0.9809579672635301\n",
      "Train Loss After a Epoch 5: 6.015921326221854 %\n",
      "Train Acc: 98.11166666666666 %\n",
      "--------------Running On validation data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       460\n",
      "           1       0.96      1.00      0.98       571\n",
      "           2       0.98      0.98      0.98       530\n",
      "           3       0.97      0.98      0.98       500\n",
      "           4       0.99      0.98      0.98       500\n",
      "           5       0.92      1.00      0.96       456\n",
      "           6       1.00      0.90      0.95       462\n",
      "           7       0.98      0.96      0.97       512\n",
      "           8       0.99      0.95      0.97       489\n",
      "           9       0.97      0.97      0.97       520\n",
      "\n",
      "    accuracy                           0.97      5000\n",
      "   macro avg       0.97      0.97      0.97      5000\n",
      "weighted avg       0.97      0.97      0.97      5000\n",
      "\n",
      "macro f1 validation set: \n",
      "0.9716813204487771\n",
      "Validation Loss After a Epoch 5: 8.978521996031501 %\n",
      "Validation Acc: 97.22 %\n",
      "Running Epoch: 6\n",
      "Progress 100.0%\n",
      "--------------Running On all training data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5923\n",
      "           1       0.97      1.00      0.98      6742\n",
      "           2       0.99      0.98      0.99      5958\n",
      "           3       0.99      0.98      0.98      6131\n",
      "           4       0.98      0.99      0.99      5842\n",
      "           5       0.95      0.99      0.97      5421\n",
      "           6       1.00      0.96      0.98      5918\n",
      "           7       0.99      0.98      0.99      6265\n",
      "           8       0.99      0.96      0.98      5851\n",
      "           9       0.98      0.98      0.98      5949\n",
      "\n",
      "    accuracy                           0.98     60000\n",
      "   macro avg       0.98      0.98      0.98     60000\n",
      "weighted avg       0.98      0.98      0.98     60000\n",
      "\n",
      "macro f1 train set: \n",
      "0.9825619416190932\n",
      "Train Loss After a Epoch 6: 5.4267641518525584 %\n",
      "Train Acc: 98.27 %\n",
      "--------------Running On validation data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       460\n",
      "           1       0.96      1.00      0.98       571\n",
      "           2       0.98      0.98      0.98       530\n",
      "           3       0.98      0.98      0.98       500\n",
      "           4       0.99      0.99      0.99       500\n",
      "           5       0.92      1.00      0.96       456\n",
      "           6       1.00      0.90      0.95       462\n",
      "           7       0.98      0.96      0.97       512\n",
      "           8       0.99      0.95      0.97       489\n",
      "           9       0.97      0.97      0.97       520\n",
      "\n",
      "    accuracy                           0.97      5000\n",
      "   macro avg       0.97      0.97      0.97      5000\n",
      "weighted avg       0.97      0.97      0.97      5000\n",
      "\n",
      "macro f1 validation set: \n",
      "0.9729236579301992\n",
      "Validation Loss After a Epoch 6: 8.451944891857488 %\n",
      "Validation Acc: 97.34 %\n",
      "Running Epoch: 7\n",
      "Progress 100.0%\n",
      "--------------Running On all training data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5923\n",
      "           1       0.98      1.00      0.99      6742\n",
      "           2       0.99      0.99      0.99      5958\n",
      "           3       0.99      0.98      0.98      6131\n",
      "           4       0.98      0.99      0.99      5842\n",
      "           5       0.96      0.99      0.98      5421\n",
      "           6       1.00      0.97      0.98      5918\n",
      "           7       0.99      0.99      0.99      6265\n",
      "           8       0.99      0.97      0.98      5851\n",
      "           9       0.98      0.98      0.98      5949\n",
      "\n",
      "    accuracy                           0.99     60000\n",
      "   macro avg       0.99      0.99      0.99     60000\n",
      "weighted avg       0.99      0.99      0.99     60000\n",
      "\n",
      "macro f1 train set: \n",
      "0.9852812418855473\n",
      "Train Loss After a Epoch 7: 4.572200199920169 %\n",
      "Train Acc: 98.54 %\n",
      "--------------Running On validation data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       460\n",
      "           1       0.96      1.00      0.98       571\n",
      "           2       0.98      0.98      0.98       530\n",
      "           3       0.98      0.98      0.98       500\n",
      "           4       0.99      0.99      0.99       500\n",
      "           5       0.94      1.00      0.97       456\n",
      "           6       1.00      0.92      0.95       462\n",
      "           7       0.98      0.97      0.97       512\n",
      "           8       0.99      0.96      0.98       489\n",
      "           9       0.97      0.97      0.97       520\n",
      "\n",
      "    accuracy                           0.98      5000\n",
      "   macro avg       0.98      0.98      0.98      5000\n",
      "weighted avg       0.98      0.98      0.98      5000\n",
      "\n",
      "macro f1 validation set: \n",
      "0.9756484099738255\n",
      "Validation Loss After a Epoch 7: 7.408681690898764 %\n",
      "Validation Acc: 97.6 %\n",
      "Running Epoch: 8\n",
      "Progress 100.0%\n",
      "--------------Running On all training data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5923\n",
      "           1       0.98      1.00      0.99      6742\n",
      "           2       0.99      0.99      0.99      5958\n",
      "           3       0.99      0.98      0.99      6131\n",
      "           4       0.98      1.00      0.99      5842\n",
      "           5       0.97      0.99      0.98      5421\n",
      "           6       1.00      0.97      0.99      5918\n",
      "           7       0.99      0.99      0.99      6265\n",
      "           8       0.99      0.98      0.98      5851\n",
      "           9       0.99      0.98      0.99      5949\n",
      "\n",
      "    accuracy                           0.99     60000\n",
      "   macro avg       0.99      0.99      0.99     60000\n",
      "weighted avg       0.99      0.99      0.99     60000\n",
      "\n",
      "macro f1 train set: \n",
      "0.9874125612330878\n",
      "Train Loss After a Epoch 8: 3.9811503194822455 %\n",
      "Train Acc: 98.75 %\n",
      "--------------Running On validation data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       460\n",
      "           1       0.97      1.00      0.98       571\n",
      "           2       0.98      0.99      0.99       530\n",
      "           3       0.98      0.99      0.98       500\n",
      "           4       0.99      0.99      0.99       500\n",
      "           5       0.95      1.00      0.97       456\n",
      "           6       1.00      0.93      0.96       462\n",
      "           7       0.99      0.97      0.98       512\n",
      "           8       0.99      0.97      0.98       489\n",
      "           9       0.98      0.97      0.97       520\n",
      "\n",
      "    accuracy                           0.98      5000\n",
      "   macro avg       0.98      0.98      0.98      5000\n",
      "weighted avg       0.98      0.98      0.98      5000\n",
      "\n",
      "macro f1 validation set: \n",
      "0.978495075538512\n",
      "Validation Loss After a Epoch 8: 6.750210883600776 %\n",
      "Validation Acc: 97.88 %\n",
      "Running Epoch: 9\n",
      "Progress 100.0%\n",
      "--------------Running On all training data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5923\n",
      "           1       0.98      1.00      0.99      6742\n",
      "           2       0.99      0.99      0.99      5958\n",
      "           3       1.00      0.98      0.99      6131\n",
      "           4       0.98      1.00      0.99      5842\n",
      "           5       0.97      0.99      0.98      5421\n",
      "           6       1.00      0.98      0.99      5918\n",
      "           7       0.99      0.99      0.99      6265\n",
      "           8       0.99      0.98      0.98      5851\n",
      "           9       0.99      0.98      0.99      5949\n",
      "\n",
      "    accuracy                           0.99     60000\n",
      "   macro avg       0.99      0.99      0.99     60000\n",
      "weighted avg       0.99      0.99      0.99     60000\n",
      "\n",
      "macro f1 train set: \n",
      "0.9882513848018635\n",
      "Train Loss After a Epoch 9: 3.704347278958954 %\n",
      "Train Acc: 98.83333333333333 %\n",
      "--------------Running On validation data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       460\n",
      "           1       0.97      1.00      0.98       571\n",
      "           2       0.98      0.99      0.98       530\n",
      "           3       0.99      0.98      0.98       500\n",
      "           4       0.98      0.99      0.99       500\n",
      "           5       0.95      1.00      0.97       456\n",
      "           6       1.00      0.93      0.96       462\n",
      "           7       0.99      0.97      0.98       512\n",
      "           8       0.99      0.97      0.98       489\n",
      "           9       0.98      0.96      0.97       520\n",
      "\n",
      "    accuracy                           0.98      5000\n",
      "   macro avg       0.98      0.98      0.98      5000\n",
      "weighted avg       0.98      0.98      0.98      5000\n",
      "\n",
      "macro f1 validation set: \n",
      "0.9791019366742685\n",
      "Validation Loss After a Epoch 9: 6.563879384769134 %\n",
      "Validation Acc: 97.94 %\n",
      "Running Epoch: 10\n",
      "Progress 100.0%\n",
      "--------------Running On all training data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      5923\n",
      "           1       0.99      1.00      0.99      6742\n",
      "           2       0.99      0.99      0.99      5958\n",
      "           3       1.00      0.98      0.99      6131\n",
      "           4       0.98      1.00      0.99      5842\n",
      "           5       0.98      0.99      0.99      5421\n",
      "           6       1.00      0.98      0.99      5918\n",
      "           7       0.99      0.99      0.99      6265\n",
      "           8       0.99      0.98      0.98      5851\n",
      "           9       0.99      0.98      0.99      5949\n",
      "\n",
      "    accuracy                           0.99     60000\n",
      "   macro avg       0.99      0.99      0.99     60000\n",
      "weighted avg       0.99      0.99      0.99     60000\n",
      "\n",
      "macro f1 train set: \n",
      "0.9889705399086214\n",
      "Train Loss After a Epoch 10: 3.3861811771113173 %\n",
      "Train Acc: 98.905 %\n",
      "--------------Running On validation data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       460\n",
      "           1       0.97      1.00      0.99       571\n",
      "           2       0.98      0.99      0.99       530\n",
      "           3       0.99      0.98      0.98       500\n",
      "           4       0.97      1.00      0.99       500\n",
      "           5       0.96      1.00      0.98       456\n",
      "           6       1.00      0.94      0.97       462\n",
      "           7       0.99      0.97      0.98       512\n",
      "           8       1.00      0.97      0.98       489\n",
      "           9       0.99      0.96      0.97       520\n",
      "\n",
      "    accuracy                           0.98      5000\n",
      "   macro avg       0.98      0.98      0.98      5000\n",
      "weighted avg       0.98      0.98      0.98      5000\n",
      "\n",
      "macro f1 validation set: \n",
      "0.9805342423441553\n",
      "Validation Loss After a Epoch 10: 6.2535987225303735 %\n",
      "Validation Acc: 98.08 %\n",
      "Finished Training!\n",
      "--------------Running On testing data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       520\n",
      "           1       1.00      1.00      1.00       564\n",
      "           2       0.99      0.99      0.99       502\n",
      "           3       0.99      0.99      0.99       510\n",
      "           4       0.99      1.00      1.00       482\n",
      "           5       0.99      0.99      0.99       436\n",
      "           6       1.00      0.99      0.99       496\n",
      "           7       0.99      0.99      0.99       516\n",
      "           8       0.99      0.99      0.99       485\n",
      "           9       1.00      0.99      0.99       489\n",
      "\n",
      "    accuracy                           0.99      5000\n",
      "   macro avg       0.99      0.99      0.99      5000\n",
      "weighted avg       0.99      0.99      0.99      5000\n",
      "\n",
      "macro f1 test set: \n",
      "0.9927239939615535\n",
      "Train Loss : 2.0414997431462543 %\n",
      "Test Acc: 99.28 %\n"
     ]
    }
   ],
   "source": [
    "cnn.train(training_data=(X_train, Y_train), epochs=10, learning_rate=0.02, test_data=(X_test, Y_test), mini_batch_size=32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "0.1699197735721404"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16.99197735721404 / 100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn.plot_metrics()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing for cifer 10 data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "(10000,)\n",
      "(10000,)\n",
      "(10000,)\n",
      "(10000,)\n",
      "(10000,)\n",
      "Shape: (50000, 32, 32, 3)\n",
      "Shape: (50000, 1)\n",
      "Shape: (10000, 32, 32, 3)\n",
      "Shape: (10000, 1)\n",
      "(50000, 32, 32, 3)\n",
      "(50000, 10)\n"
     ]
    }
   ],
   "source": [
    "cifer_dataloader = Cifer10DataLoader('/home/akil/Work/Work/Academics/4-2/ML/Assignment-3/dataset/cifer-10/cifar-10-python/cifar-10-batches-py')\n",
    "cifer_dataloader.concatenate_data()\n",
    "cifer_dataloader.preprocess_data()\n",
    "print(cifer_dataloader.data['train_images'].shape)\n",
    "X_train = cifer_dataloader.data['train_images']\n",
    "Y_train = cifer_dataloader.data['train_labels']\n",
    "X_test = cifer_dataloader.data['test_images']\n",
    "Y_test = cifer_dataloader.data['test_labels']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Conv 6 5 1 2', 'ReLU', 'Pool 2 2', 'Conv 12 5 1 0', 'ReLU', 'Pool 2 2', 'Conv 100 5 1 0', 'ReLU', 'FC 10', 'Softmax']\n",
      "The layer name:  Conv2D__4 5\n",
      "The layer name:  Conv2D__5 6\n",
      "The layer name:  Conv2D__6 7\n",
      "(32, 32, 6)\n",
      "(12, 12, 12)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "cnn = Model()\n",
    "cnn.add(Utility.read_model_config('./input.txt', cifer_dataloader))\n",
    "cnn.compile(cost_function=CrossEntropyLoss())\n",
    "cnn.initializer_layer_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Epoch: 1\n",
      "Progress 100.1%\n",
      "--------------Running On all training data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.32      0.40      5000\n",
      "           1       0.33      0.83      0.47      5000\n",
      "           2       0.28      0.18      0.22      5000\n",
      "           3       0.34      0.29      0.31      5000\n",
      "           4       0.37      0.35      0.36      5000\n",
      "           5       0.50      0.19      0.28      5000\n",
      "           6       0.38      0.61      0.46      5000\n",
      "           7       0.39      0.58      0.47      5000\n",
      "           8       0.67      0.19      0.29      5000\n",
      "           9       0.51      0.32      0.39      5000\n",
      "\n",
      "    accuracy                           0.39     50000\n",
      "   macro avg       0.43      0.39      0.37     50000\n",
      "weighted avg       0.43      0.39      0.37     50000\n",
      "\n",
      "macro f1 train set: \n",
      "0.36598784563920356\n",
      "Train Loss After a Epoch 1: 167.39896270480165 %\n",
      "Train Acc: 38.68 %\n",
      "--------------Running On validation data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.32      0.39       488\n",
      "           1       0.35      0.86      0.50       505\n",
      "           2       0.27      0.19      0.23       512\n",
      "           3       0.32      0.28      0.30       497\n",
      "           4       0.38      0.35      0.37       507\n",
      "           5       0.48      0.18      0.27       488\n",
      "           6       0.39      0.64      0.49       491\n",
      "           7       0.40      0.62      0.49       495\n",
      "           8       0.72      0.21      0.33       504\n",
      "           9       0.54      0.33      0.41       513\n",
      "\n",
      "    accuracy                           0.40      5000\n",
      "   macro avg       0.44      0.40      0.38      5000\n",
      "weighted avg       0.44      0.40      0.38      5000\n",
      "\n",
      "macro f1 validation set: \n",
      "0.37588171126918646\n",
      "Validation Loss After a Epoch 1: 165.04266233341136 %\n",
      "Validation Acc: 39.800000000000004 %\n",
      "Running Epoch: 2\n",
      "Progress 100.1%\n",
      "--------------Running On all training data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.42      0.47      5000\n",
      "           1       0.29      0.92      0.44      5000\n",
      "           2       0.39      0.28      0.32      5000\n",
      "           3       0.40      0.28      0.33      5000\n",
      "           4       0.44      0.37      0.40      5000\n",
      "           5       0.52      0.24      0.33      5000\n",
      "           6       0.50      0.56      0.53      5000\n",
      "           7       0.43      0.63      0.51      5000\n",
      "           8       0.76      0.15      0.25      5000\n",
      "           9       0.51      0.29      0.37      5000\n",
      "\n",
      "    accuracy                           0.41     50000\n",
      "   macro avg       0.48      0.41      0.40     50000\n",
      "weighted avg       0.48      0.41      0.40     50000\n",
      "\n",
      "macro f1 train set: \n",
      "0.3961705371014529\n",
      "Train Loss After a Epoch 2: 160.50559750774525 %\n",
      "Train Acc: 41.442 %\n",
      "--------------Running On validation data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.41      0.45       488\n",
      "           1       0.31      0.92      0.46       505\n",
      "           2       0.37      0.28      0.32       512\n",
      "           3       0.41      0.28      0.33       497\n",
      "           4       0.47      0.38      0.42       507\n",
      "           5       0.48      0.23      0.31       488\n",
      "           6       0.50      0.59      0.54       491\n",
      "           7       0.42      0.62      0.50       495\n",
      "           8       0.78      0.18      0.29       504\n",
      "           9       0.51      0.28      0.37       513\n",
      "\n",
      "    accuracy                           0.42      5000\n",
      "   macro avg       0.48      0.42      0.40      5000\n",
      "weighted avg       0.47      0.42      0.40      5000\n",
      "\n",
      "macro f1 validation set: \n",
      "0.3996206798721667\n",
      "Validation Loss After a Epoch 2: 158.66425013985994 %\n",
      "Validation Acc: 41.78 %\n",
      "Running Epoch: 3\n",
      "Progress 100.1%\n",
      "--------------Running On all training data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.49      0.54      5000\n",
      "           1       0.35      0.91      0.51      5000\n",
      "           2       0.46      0.28      0.35      5000\n",
      "           3       0.46      0.29      0.35      5000\n",
      "           4       0.44      0.47      0.45      5000\n",
      "           5       0.53      0.32      0.40      5000\n",
      "           6       0.55      0.60      0.58      5000\n",
      "           7       0.44      0.71      0.55      5000\n",
      "           8       0.82      0.29      0.43      5000\n",
      "           9       0.56      0.37      0.44      5000\n",
      "\n",
      "    accuracy                           0.47     50000\n",
      "   macro avg       0.52      0.47      0.46     50000\n",
      "weighted avg       0.52      0.47      0.46     50000\n",
      "\n",
      "macro f1 train set: \n",
      "0.4598198847935907\n",
      "Train Loss After a Epoch 3: 145.67136282321772 %\n",
      "Train Acc: 47.286 %\n",
      "--------------Running On validation data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.48      0.51       488\n",
      "           1       0.37      0.91      0.52       505\n",
      "           2       0.42      0.26      0.32       512\n",
      "           3       0.48      0.29      0.36       497\n",
      "           4       0.45      0.46      0.46       507\n",
      "           5       0.48      0.30      0.37       488\n",
      "           6       0.54      0.64      0.59       491\n",
      "           7       0.43      0.70      0.53       495\n",
      "           8       0.84      0.33      0.47       504\n",
      "           9       0.57      0.35      0.44       513\n",
      "\n",
      "    accuracy                           0.47      5000\n",
      "   macro avg       0.51      0.47      0.46      5000\n",
      "weighted avg       0.51      0.47      0.46      5000\n",
      "\n",
      "macro f1 validation set: \n",
      "0.45704178034083087\n",
      "Validation Loss After a Epoch 3: 144.95128373498815 %\n",
      "Validation Acc: 47.08 %\n",
      "Running Epoch: 4\n",
      "Progress 100.1%\n",
      "--------------Running On all training data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.58      0.57      5000\n",
      "           1       0.35      0.93      0.50      5000\n",
      "           2       0.50      0.28      0.36      5000\n",
      "           3       0.48      0.28      0.35      5000\n",
      "           4       0.49      0.46      0.47      5000\n",
      "           5       0.57      0.31      0.40      5000\n",
      "           6       0.59      0.60      0.60      5000\n",
      "           7       0.48      0.71      0.57      5000\n",
      "           8       0.81      0.37      0.50      5000\n",
      "           9       0.56      0.39      0.46      5000\n",
      "\n",
      "    accuracy                           0.49     50000\n",
      "   macro avg       0.54      0.49      0.48     50000\n",
      "weighted avg       0.54      0.49      0.48     50000\n",
      "\n",
      "macro f1 train set: \n",
      "0.4783648167271579\n",
      "Train Loss After a Epoch 4: 142.6388295235764 %\n",
      "Train Acc: 48.984 %\n",
      "--------------Running On validation data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.60      0.55       488\n",
      "           1       0.36      0.92      0.52       505\n",
      "           2       0.45      0.24      0.31       512\n",
      "           3       0.51      0.29      0.37       497\n",
      "           4       0.49      0.44      0.46       507\n",
      "           5       0.55      0.30      0.39       488\n",
      "           6       0.59      0.62      0.61       491\n",
      "           7       0.46      0.69      0.55       495\n",
      "           8       0.79      0.39      0.53       504\n",
      "           9       0.54      0.36      0.43       513\n",
      "\n",
      "    accuracy                           0.48      5000\n",
      "   macro avg       0.52      0.48      0.47      5000\n",
      "weighted avg       0.52      0.48      0.47      5000\n",
      "\n",
      "macro f1 validation set: \n",
      "0.4710290602313606\n",
      "Validation Loss After a Epoch 4: 143.81502227789156 %\n",
      "Validation Acc: 48.4 %\n",
      "Running Epoch: 5\n",
      "Progress 100.1%\n",
      "--------------Running On all training data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.65      0.60      5000\n",
      "           1       0.40      0.93      0.56      5000\n",
      "           2       0.53      0.33      0.41      5000\n",
      "           3       0.50      0.30      0.38      5000\n",
      "           4       0.50      0.50      0.50      5000\n",
      "           5       0.59      0.33      0.43      5000\n",
      "           6       0.62      0.64      0.63      5000\n",
      "           7       0.50      0.74      0.60      5000\n",
      "           8       0.82      0.41      0.55      5000\n",
      "           9       0.62      0.42      0.50      5000\n",
      "\n",
      "    accuracy                           0.53     50000\n",
      "   macro avg       0.56      0.53      0.51     50000\n",
      "weighted avg       0.56      0.53      0.51     50000\n",
      "\n",
      "macro f1 train set: \n",
      "0.5137157777026563\n",
      "Train Loss After a Epoch 5: 132.99426974687017 %\n",
      "Train Acc: 52.534000000000006 %\n",
      "--------------Running On validation data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.65      0.57       488\n",
      "           1       0.41      0.92      0.57       505\n",
      "           2       0.48      0.29      0.36       512\n",
      "           3       0.54      0.31      0.40       497\n",
      "           4       0.52      0.49      0.50       507\n",
      "           5       0.56      0.33      0.41       488\n",
      "           6       0.61      0.65      0.63       491\n",
      "           7       0.47      0.72      0.57       495\n",
      "           8       0.81      0.45      0.58       504\n",
      "           9       0.59      0.37      0.45       513\n",
      "\n",
      "    accuracy                           0.52      5000\n",
      "   macro avg       0.55      0.52      0.50      5000\n",
      "weighted avg       0.55      0.52      0.50      5000\n",
      "\n",
      "macro f1 validation set: \n",
      "0.5040606379887599\n",
      "Validation Loss After a Epoch 5: 136.87281806149818 %\n",
      "Validation Acc: 51.66 %\n",
      "Running Epoch: 6\n",
      "Progress 100.1%\n",
      "--------------Running On all training data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.69      0.63      5000\n",
      "           1       0.45      0.92      0.60      5000\n",
      "           2       0.54      0.36      0.44      5000\n",
      "           3       0.53      0.31      0.39      5000\n",
      "           4       0.52      0.53      0.53      5000\n",
      "           5       0.61      0.36      0.46      5000\n",
      "           6       0.62      0.68      0.65      5000\n",
      "           7       0.52      0.77      0.62      5000\n",
      "           8       0.81      0.51      0.63      5000\n",
      "           9       0.67      0.46      0.55      5000\n",
      "\n",
      "    accuracy                           0.56     50000\n",
      "   macro avg       0.59      0.56      0.55     50000\n",
      "weighted avg       0.59      0.56      0.55     50000\n",
      "\n",
      "macro f1 train set: \n",
      "0.5487821303627183\n",
      "Train Loss After a Epoch 6: 123.6535021447636 %\n",
      "Train Acc: 55.998000000000005 %\n",
      "--------------Running On validation data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.69      0.60       488\n",
      "           1       0.45      0.91      0.60       505\n",
      "           2       0.48      0.32      0.38       512\n",
      "           3       0.57      0.30      0.39       497\n",
      "           4       0.52      0.50      0.51       507\n",
      "           5       0.56      0.35      0.43       488\n",
      "           6       0.62      0.69      0.65       491\n",
      "           7       0.48      0.74      0.58       495\n",
      "           8       0.78      0.53      0.63       504\n",
      "           9       0.63      0.38      0.47       513\n",
      "\n",
      "    accuracy                           0.54      5000\n",
      "   macro avg       0.56      0.54      0.53      5000\n",
      "weighted avg       0.56      0.54      0.52      5000\n",
      "\n",
      "macro f1 validation set: \n",
      "0.5252170531394291\n",
      "Validation Loss After a Epoch 6: 130.54395237956032 %\n",
      "Validation Acc: 53.86 %\n",
      "Running Epoch: 7\n",
      "Progress 100.1%\n",
      "--------------Running On all training data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.71      0.64      5000\n",
      "           1       0.44      0.93      0.60      5000\n",
      "           2       0.56      0.40      0.47      5000\n",
      "           3       0.54      0.31      0.39      5000\n",
      "           4       0.57      0.49      0.53      5000\n",
      "           5       0.62      0.37      0.46      5000\n",
      "           6       0.61      0.70      0.65      5000\n",
      "           7       0.55      0.75      0.64      5000\n",
      "           8       0.80      0.56      0.66      5000\n",
      "           9       0.66      0.48      0.55      5000\n",
      "\n",
      "    accuracy                           0.57     50000\n",
      "   macro avg       0.59      0.57      0.56     50000\n",
      "weighted avg       0.59      0.57      0.56     50000\n",
      "\n",
      "macro f1 train set: \n",
      "0.5585908423991086\n",
      "Train Loss After a Epoch 7: 121.70662158886071 %\n",
      "Train Acc: 56.934 %\n",
      "--------------Running On validation data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.69      0.59       488\n",
      "           1       0.44      0.93      0.60       505\n",
      "           2       0.48      0.34      0.40       512\n",
      "           3       0.54      0.29      0.38       497\n",
      "           4       0.56      0.46      0.51       507\n",
      "           5       0.57      0.33      0.42       488\n",
      "           6       0.60      0.70      0.65       491\n",
      "           7       0.49      0.68      0.57       495\n",
      "           8       0.76      0.57      0.65       504\n",
      "           9       0.62      0.38      0.47       513\n",
      "\n",
      "    accuracy                           0.54      5000\n",
      "   macro avg       0.56      0.54      0.52      5000\n",
      "weighted avg       0.56      0.54      0.52      5000\n",
      "\n",
      "macro f1 validation set: \n",
      "0.523245824688036\n",
      "Validation Loss After a Epoch 7: 131.27856150075954 %\n",
      "Validation Acc: 53.72 %\n",
      "Running Epoch: 8\n",
      "Progress 100.1%\n",
      "--------------Running On all training data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.71      0.67      5000\n",
      "           1       0.48      0.92      0.63      5000\n",
      "           2       0.59      0.39      0.47      5000\n",
      "           3       0.56      0.33      0.41      5000\n",
      "           4       0.58      0.51      0.55      5000\n",
      "           5       0.61      0.39      0.48      5000\n",
      "           6       0.60      0.74      0.67      5000\n",
      "           7       0.54      0.79      0.64      5000\n",
      "           8       0.81      0.61      0.70      5000\n",
      "           9       0.70      0.51      0.59      5000\n",
      "\n",
      "    accuracy                           0.59     50000\n",
      "   macro avg       0.61      0.59      0.58     50000\n",
      "weighted avg       0.61      0.59      0.58     50000\n",
      "\n",
      "macro f1 train set: \n",
      "0.5797792067224454\n",
      "Train Loss After a Epoch 8: 115.31323623046994 %\n",
      "Train Acc: 59.099999999999994 %\n",
      "--------------Running On validation data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.70      0.63       488\n",
      "           1       0.47      0.91      0.62       505\n",
      "           2       0.51      0.31      0.39       512\n",
      "           3       0.55      0.30      0.39       497\n",
      "           4       0.55      0.47      0.51       507\n",
      "           5       0.56      0.34      0.42       488\n",
      "           6       0.59      0.75      0.66       491\n",
      "           7       0.48      0.74      0.58       495\n",
      "           8       0.76      0.62      0.68       504\n",
      "           9       0.67      0.41      0.51       513\n",
      "\n",
      "    accuracy                           0.55      5000\n",
      "   macro avg       0.57      0.55      0.54      5000\n",
      "weighted avg       0.57      0.55      0.54      5000\n",
      "\n",
      "macro f1 validation set: \n",
      "0.5385703812574214\n",
      "Validation Loss After a Epoch 8: 126.55374506565357 %\n",
      "Validation Acc: 55.379999999999995 %\n",
      "Running Epoch: 9\n",
      "Progress 100.1%\n",
      "--------------Running On all training data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.74      0.68      5000\n",
      "           1       0.53      0.91      0.67      5000\n",
      "           2       0.56      0.45      0.50      5000\n",
      "           3       0.54      0.37      0.44      5000\n",
      "           4       0.57      0.55      0.56      5000\n",
      "           5       0.61      0.40      0.48      5000\n",
      "           6       0.65      0.72      0.68      5000\n",
      "           7       0.56      0.79      0.66      5000\n",
      "           8       0.81      0.64      0.71      5000\n",
      "           9       0.75      0.52      0.61      5000\n",
      "\n",
      "    accuracy                           0.61     50000\n",
      "   macro avg       0.62      0.61      0.60     50000\n",
      "weighted avg       0.62      0.61      0.60     50000\n",
      "\n",
      "macro f1 train set: \n",
      "0.5996397097456275\n",
      "Train Loss After a Epoch 9: 110.3121898204148 %\n",
      "Train Acc: 60.848 %\n",
      "--------------Running On validation data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.72      0.64       488\n",
      "           1       0.51      0.88      0.64       505\n",
      "           2       0.49      0.38      0.43       512\n",
      "           3       0.55      0.34      0.42       497\n",
      "           4       0.55      0.52      0.54       507\n",
      "           5       0.54      0.35      0.42       488\n",
      "           6       0.64      0.71      0.67       491\n",
      "           7       0.50      0.75      0.60       495\n",
      "           8       0.76      0.63      0.69       504\n",
      "           9       0.70      0.42      0.53       513\n",
      "\n",
      "    accuracy                           0.57      5000\n",
      "   macro avg       0.58      0.57      0.56      5000\n",
      "weighted avg       0.58      0.57      0.56      5000\n",
      "\n",
      "macro f1 validation set: \n",
      "0.5577510268761537\n",
      "Validation Loss After a Epoch 9: 123.16192896718734 %\n",
      "Validation Acc: 56.940000000000005 %\n",
      "Running Epoch: 10\n",
      "Progress 100.1%\n",
      "--------------Running On all training data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.74      0.68      5000\n",
      "           1       0.54      0.91      0.67      5000\n",
      "           2       0.55      0.47      0.51      5000\n",
      "           3       0.54      0.39      0.45      5000\n",
      "           4       0.59      0.55      0.57      5000\n",
      "           5       0.62      0.42      0.50      5000\n",
      "           6       0.65      0.73      0.69      5000\n",
      "           7       0.58      0.79      0.67      5000\n",
      "           8       0.81      0.63      0.71      5000\n",
      "           9       0.76      0.53      0.62      5000\n",
      "\n",
      "    accuracy                           0.62     50000\n",
      "   macro avg       0.63      0.62      0.61     50000\n",
      "weighted avg       0.63      0.62      0.61     50000\n",
      "\n",
      "macro f1 train set: \n",
      "0.6072016236001316\n",
      "Train Loss After a Epoch 10: 108.2219689334446 %\n",
      "Train Acc: 61.522 %\n",
      "--------------Running On validation data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.72      0.63       488\n",
      "           1       0.52      0.88      0.65       505\n",
      "           2       0.49      0.39      0.43       512\n",
      "           3       0.54      0.36      0.43       497\n",
      "           4       0.57      0.50      0.54       507\n",
      "           5       0.54      0.36      0.43       488\n",
      "           6       0.62      0.72      0.67       491\n",
      "           7       0.51      0.75      0.61       495\n",
      "           8       0.76      0.62      0.69       504\n",
      "           9       0.71      0.43      0.54       513\n",
      "\n",
      "    accuracy                           0.57      5000\n",
      "   macro avg       0.58      0.57      0.56      5000\n",
      "weighted avg       0.58      0.57      0.56      5000\n",
      "\n",
      "macro f1 validation set: \n",
      "0.5614154977872421\n",
      "Validation Loss After a Epoch 10: 122.48459284288487 %\n",
      "Validation Acc: 57.24 %\n",
      "Finished Training!\n",
      "--------------Running On testing data-----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.76      0.69       512\n",
      "           1       0.51      0.87      0.64       495\n",
      "           2       0.51      0.43      0.46       488\n",
      "           3       0.47      0.32      0.38       503\n",
      "           4       0.52      0.47      0.49       493\n",
      "           5       0.60      0.37      0.46       512\n",
      "           6       0.63      0.74      0.68       509\n",
      "           7       0.52      0.75      0.62       505\n",
      "           8       0.77      0.58      0.66       496\n",
      "           9       0.72      0.48      0.57       487\n",
      "\n",
      "    accuracy                           0.58      5000\n",
      "   macro avg       0.59      0.58      0.57      5000\n",
      "weighted avg       0.59      0.58      0.57      5000\n",
      "\n",
      "macro f1 test set: \n",
      "0.5667847726177111\n",
      "Train Loss : 124.21472112692989 %\n",
      "Test Acc: 57.8 %\n"
     ]
    }
   ],
   "source": [
    "cnn.train(training_data=(X_train, Y_train), epochs=10, learning_rate=0.02, test_data=(X_test, Y_test),mini_batch_size=32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn.plot_metrics()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experiments"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dense = DenseLayer(num_units=4)\n",
    "dense.W = np.array( [[ 1.4401747,   0.72498046, -0.05727674],\n",
    "                     [-1.15246919, -0.39990891,  0.44136903],\n",
    "                     [ 1.14171484, -1.41891945,  0.73059128],\n",
    "                     [ 0.60664542, -0.08249916, -1.05893566]])\n",
    "dense.W.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "outputs": [
    {
     "data": {
      "text/plain": "(1, 3)"
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([ [0.83351854,  -0.55429203,   0.0702855 ]])\n",
    "a.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "outputs": [
    {
     "data": {
      "text/plain": "(4, 1)"
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense.b = np.array( [[-0.64243089], [0.51146315], [-0.17120088], [1.10775354]])\n",
    "dense.b.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_prev_layer shape: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "dense.forward(a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3)\n",
      "(4, 1)\n",
      "(4, 1)\n",
      "[[ 0.12678218 -0.08431048  0.01069076]\n",
      " [-0.16374732  0.1088924  -0.01380781]\n",
      " [ 1.34887082 -0.89700266  0.11374199]\n",
      " [ 1.32088062 -0.8783891   0.11138175]]\n",
      "[[ 0.15210481]\n",
      " [-0.19645312]\n",
      " [ 1.61828532]\n",
      " [ 1.58470455]]\n"
     ]
    }
   ],
   "source": [
    "dz = dense.output_tensor\n",
    "dense.backward(dz)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "outputs": [],
   "source": [
    "s = np.array([[-0.39692968,  1.78981015, -0.54303206,  0.14530002,  1.42375341]])\n",
    "s = s.reshape(1, -1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax tensor shape: (1, 5)\n",
      "softmax exp shape (1, 5)\n",
      "softmax sum shape: (1, 1)\n",
      "[[0.05357302 0.47712828 0.0462908  0.09213688 0.33087103]]\n"
     ]
    }
   ],
   "source": [
    "soft = SoftmaxActivation()\n",
    "print(soft.forward(s))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he: paramaters:  784\n",
      "(28, 28, 6)\n",
      "he: paramaters:  1176\n",
      "(10, 10, 12)\n",
      "he: paramaters:  300\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "X = np.random.randn(1,28,28,1)\n",
    "Y = np.random.randn(1,10)\n",
    "cnn = Model()\n",
    "np.random.seed(1)\n",
    "\n",
    "cnn = Model()\n",
    "cnn.add(layer_list=[\n",
    "    InputLayer(input_dimension=(mnist.size, mnist.size, mnist.color_channel), is_trainable=False, layer_name='Input'),\n",
    "    Convolution2D(num_out_channel=6, filter_size=5, stride=1, padding_size=2),\n",
    "    ReLUActivation(),\n",
    "    MaxPool(filter_size=2, stride=2),\n",
    "    Convolution2D(num_out_channel=12, filter_size=5, stride=1, padding_size=0),\n",
    "    ReLUActivation(),\n",
    "    MaxPool(filter_size=2, stride=2),\n",
    "    Convolution2D(num_out_channel=100, filter_size=5, stride=1, padding_size=0),\n",
    "    ReLUActivation(),\n",
    "    Flatten(),\n",
    "    DenseLayer(10),\n",
    "    SoftmaxActivation()\n",
    "])\n",
    "cnn.compile(optimizer=GradientDescent(), cost_function=CrossEntropyLoss())\n",
    "cnn.initializer_layer_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Epoch: 0\n",
      "Forward for layer Conv2D__1\n",
      "(1, 28, 28, 1)\n",
      "Forward for layer ReLU__1\n",
      "Relu Input Tensor Shape:  (1, 28, 28, 6)\n",
      "Forward for layer MaxPool__1\n",
      "Forward for layer Conv2D__1\n",
      "(1, 14, 14, 6)\n",
      "Forward for layer ReLU__1\n",
      "Relu Input Tensor Shape:  (1, 10, 10, 12)\n",
      "Forward for layer MaxPool__1\n",
      "Forward for layer Conv2D__1\n",
      "(1, 5, 5, 12)\n",
      "Forward for layer ReLU__1\n",
      "Relu Input Tensor Shape:  (1, 1, 1, 100)\n",
      "Forward for layer Flatten__1\n",
      "Forward for layer Dense__1\n",
      "A_prev_layer shape: (1, 100)\n",
      "Forward for layer Softmax__1\n",
      "softmax tensor shape: (1, 10)\n",
      "softmax exp shape (1, 10)\n",
      "softmax sum shape: (1, 1)\n",
      "final input shape (1, 10)\n",
      "final output: [[0.09049115 0.06765897 0.1529529  0.08609433 0.04750961 0.10952845\n",
      "  0.10272049 0.08826287 0.12400152 0.13077972]]\n",
      "Loss is :  -6.485603025596568\n",
      "Progress 100.0%\n",
      "\n",
      "Cost After a Epoch 1: -648.5603025596567\n",
      "Running Epoch: 1\n",
      "Forward for layer Conv2D__1\n",
      "(1, 28, 28, 1)\n",
      "Forward for layer ReLU__1\n",
      "Relu Input Tensor Shape:  (1, 28, 28, 6)\n",
      "Forward for layer MaxPool__1\n",
      "Forward for layer Conv2D__1\n",
      "(1, 14, 14, 6)\n",
      "Forward for layer ReLU__1\n",
      "Relu Input Tensor Shape:  (1, 10, 10, 12)\n",
      "Forward for layer MaxPool__1\n",
      "Forward for layer Conv2D__1\n",
      "(1, 5, 5, 12)\n",
      "Forward for layer ReLU__1\n",
      "Relu Input Tensor Shape:  (1, 1, 1, 100)\n",
      "Forward for layer Flatten__1\n",
      "Forward for layer Dense__1\n",
      "A_prev_layer shape: (1, 100)\n",
      "Forward for layer Softmax__1\n",
      "softmax tensor shape: (1, 10)\n",
      "softmax exp shape (1, 10)\n",
      "softmax sum shape: (1, 1)\n",
      "final input shape (1, 10)\n",
      "final output: [[0.09049115 0.06765897 0.1529529  0.08609433 0.04750961 0.10952845\n",
      "  0.10272049 0.08826287 0.12400152 0.13077972]]\n",
      "Loss is :  -6.485603025596568\n",
      "Progress 100.0%\n",
      "\n",
      "Cost After a Epoch 2: -648.5603025596567\n",
      "Running Epoch: 2\n",
      "Forward for layer Conv2D__1\n",
      "(1, 28, 28, 1)\n",
      "Forward for layer ReLU__1\n",
      "Relu Input Tensor Shape:  (1, 28, 28, 6)\n",
      "Forward for layer MaxPool__1\n",
      "Forward for layer Conv2D__1\n",
      "(1, 14, 14, 6)\n",
      "Forward for layer ReLU__1\n",
      "Relu Input Tensor Shape:  (1, 10, 10, 12)\n",
      "Forward for layer MaxPool__1\n",
      "Forward for layer Conv2D__1\n",
      "(1, 5, 5, 12)\n",
      "Forward for layer ReLU__1\n",
      "Relu Input Tensor Shape:  (1, 1, 1, 100)\n",
      "Forward for layer Flatten__1\n",
      "Forward for layer Dense__1\n",
      "A_prev_layer shape: (1, 100)\n",
      "Forward for layer Softmax__1\n",
      "softmax tensor shape: (1, 10)\n",
      "softmax exp shape (1, 10)\n",
      "softmax sum shape: (1, 1)\n",
      "final input shape (1, 10)\n",
      "final output: [[0.09049115 0.06765897 0.1529529  0.08609433 0.04750961 0.10952845\n",
      "  0.10272049 0.08826287 0.12400152 0.13077972]]\n",
      "Loss is :  -6.485603025596568\n",
      "Progress 100.0%\n",
      "\n",
      "Cost After a Epoch 3: -648.5603025596567\n",
      "Running Epoch: 3\n",
      "Forward for layer Conv2D__1\n",
      "(1, 28, 28, 1)\n",
      "Forward for layer ReLU__1\n",
      "Relu Input Tensor Shape:  (1, 28, 28, 6)\n",
      "Forward for layer MaxPool__1\n",
      "Forward for layer Conv2D__1\n",
      "(1, 14, 14, 6)\n",
      "Forward for layer ReLU__1\n",
      "Relu Input Tensor Shape:  (1, 10, 10, 12)\n",
      "Forward for layer MaxPool__1\n",
      "Forward for layer Conv2D__1\n",
      "(1, 5, 5, 12)\n",
      "Forward for layer ReLU__1\n",
      "Relu Input Tensor Shape:  (1, 1, 1, 100)\n",
      "Forward for layer Flatten__1\n",
      "Forward for layer Dense__1\n",
      "A_prev_layer shape: (1, 100)\n",
      "Forward for layer Softmax__1\n",
      "softmax tensor shape: (1, 10)\n",
      "softmax exp shape (1, 10)\n",
      "softmax sum shape: (1, 1)\n",
      "final input shape (1, 10)\n",
      "final output: [[0.09049115 0.06765897 0.1529529  0.08609433 0.04750961 0.10952845\n",
      "  0.10272049 0.08826287 0.12400152 0.13077972]]\n",
      "Loss is :  -6.485603025596568\n",
      "Progress 100.0%\n",
      "\n",
      "Cost After a Epoch 4: -648.5603025596567\n",
      "Running Epoch: 4\n",
      "Forward for layer Conv2D__1\n",
      "(1, 28, 28, 1)\n",
      "Forward for layer ReLU__1\n",
      "Relu Input Tensor Shape:  (1, 28, 28, 6)\n",
      "Forward for layer MaxPool__1\n",
      "Forward for layer Conv2D__1\n",
      "(1, 14, 14, 6)\n",
      "Forward for layer ReLU__1\n",
      "Relu Input Tensor Shape:  (1, 10, 10, 12)\n",
      "Forward for layer MaxPool__1\n",
      "Forward for layer Conv2D__1\n",
      "(1, 5, 5, 12)\n",
      "Forward for layer ReLU__1\n",
      "Relu Input Tensor Shape:  (1, 1, 1, 100)\n",
      "Forward for layer Flatten__1\n",
      "Forward for layer Dense__1\n",
      "A_prev_layer shape: (1, 100)\n",
      "Forward for layer Softmax__1\n",
      "softmax tensor shape: (1, 10)\n",
      "softmax exp shape (1, 10)\n",
      "softmax sum shape: (1, 1)\n",
      "final input shape (1, 10)\n",
      "final output: [[0.09049115 0.06765897 0.1529529  0.08609433 0.04750961 0.10952845\n",
      "  0.10272049 0.08826287 0.12400152 0.13077972]]\n",
      "Loss is :  -6.485603025596568\n",
      "Progress 100.0%\n",
      "\n",
      "Cost After a Epoch 5: -648.5603025596567\n",
      "Finish Training!\n"
     ]
    }
   ],
   "source": [
    "cnn.train(training_data=(X, Y), validation_data=(None, None),mini_batch_size=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conv_forward' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_102397/2488773407.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      7\u001B[0m hparameters = {\"pad\" : 2,\n\u001B[1;32m      8\u001B[0m                \"stride\": 2}\n\u001B[0;32m----> 9\u001B[0;31m \u001B[0mZ\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcache_conv\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconv_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mA_prev\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mW\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mb\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhparameters\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0;31m# Test conv_backward\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'conv_forward' is not defined"
     ]
    }
   ],
   "source": [
    "# We'll run conv_forward to initialize the 'Z' and 'cache_conv\",\n",
    "# which we'll use to test the conv_backward function\n",
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(10,4,4,3)\n",
    "W = np.random.randn(2,2,3,8)\n",
    "b = np.random.randn(1,1,1,8)\n",
    "hparameters = {\"pad\" : 2,\n",
    "               \"stride\": 2}\n",
    "Z, cache_conv = conv_forward(A_prev, W, b, hparameters)\n",
    "\n",
    "# Test conv_backward\n",
    "dA, dW, db = conv_backward_(Z, cache_conv)\n",
    "print(\"dA_mean =\", np.mean(dA))\n",
    "print(\"dW_mean =\", np.mean(dW))\n",
    "print(\"db_mean =\", np.mean(db))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(10,4,4,3) # h, w, c of previous layer\n",
    "cnn = Convolution2D(num_out_channel=8, filter_size=2, stride=2, padding_size=2)\n",
    "cnn.initialize_output_dimensions((A_prev.shape[1], A_prev.shape[2], A_prev.shape[3]))\n",
    "cnn.initialize_weights_biases()\n",
    "cnn.forward(A_prev)\n",
    "Z = cnn.get_output_tensor()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test conv_backward\n",
    "dA, dW, db = cnn.backward(Z)\n",
    "print(\"dA_mean =\", np.mean(dA))\n",
    "print(\"dW_mean =\", np.mean(dW))\n",
    "print(\"db_mean =\", np.mean(db))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Case 1: stride of 1\n",
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(5, 5, 3, 2)\n",
    "maxpool = MaxPool(filter_size=2, stride=1)\n",
    "maxpool.initialize_max_pool_params((A_prev.shape[1],A_prev.shape[2],A_prev.shape[3]))\n",
    "maxpool.forward(A_prev)\n",
    "A = maxpool.get_output_tensor()\n",
    "print('shape of A',A.shape)\n",
    "\n",
    "dA = np.random.randn(5, 4, 2, 2)\n",
    "print(dA[0,0,0,0])\n",
    "out = maxpool.backward(dA)\n",
    "print(\"mode = max\")\n",
    "print('mean of dA = ', np.mean(dA))\n",
    "print('dA_prev[1,1] = ', out[1,1])\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Case 1: stride of 1\n",
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(5, 5, 3, 2)\n",
    "maxpool = MaxPool(filter_size=2, stride=1)\n",
    "maxpool.initialize_max_pool_params((A_prev.shape[1],A_prev.shape[2],A_prev.shape[3]))\n",
    "maxpool.forward(A_prev)\n",
    "A = maxpool.get_output_tensor()\n",
    "print('shape of A',A.shape)\n",
    "\n",
    "dA = np.random.randn(5, 4, 2, 2)\n",
    "print(dA[0,0,0,0])\n",
    "out = maxpool.backward(dA)\n",
    "\n",
    "print(out.shape)\n",
    "print(\"mode = max\")\n",
    "print('mean of dA = ', np.mean(dA))\n",
    "print('dA_prev[1,1] = ', out[1,1])\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Conv 6 5 1 2', 'ReLU', 'Pool 2 2', 'Conv 12 5 1 0', 'ReLU', 'Pool 2 2', 'Conv 100 5 1 0', 'ReLU', 'Conv 14 5 1 3', 'ReLU', 'FC 15', 'FC 10', 'Softmax']\n",
      "Input\n",
      "Conv2D__1\n",
      "ReLU__19\n",
      "MaxPool__11\n",
      "Conv2D__2\n",
      "ReLU__20\n",
      "MaxPool__12\n",
      "Conv2D__3\n",
      "ReLU__21\n",
      "Conv2D__4\n",
      "ReLU__22\n",
      "Flatten__6\n",
      "Dense__9\n",
      "Dense__10\n",
      "Softmax__6\n",
      "(32, 32, 6)\n",
      "(12, 12, 12)\n",
      "Running Epoch: 1\n",
      "Progress 1.6%"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_261026/513100324.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mcnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcost_function\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mCrossEntropyLoss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mcnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minitializer_layer_params\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m \u001B[0mcnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtraining_data\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlearning_rate\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.02\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_data\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_test\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mmini_batch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m32\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/tmp/ipykernel_261026/448088773.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(self, training_data, test_data, epochs, learning_rate, mini_batch_size)\u001B[0m\n\u001B[1;32m     90\u001B[0m                 \u001B[0;31m# print(f'Batch correct: {batch_correct} out of {mini_batch_size}')\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     91\u001B[0m                 \u001B[0;31m# print(f'Batch Acc: {batch_acc * 100} %')\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 92\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward_propagation\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mY_pred\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mY\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlearning_rate\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmini_batch_size\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     93\u001B[0m                 \u001B[0;31m#train_loss = self.cost_function.compute_cost(Y_pred, Y)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     94\u001B[0m                 \u001B[0;31m#print(f'Loss per batch: {train_loss * 100} %')\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_261026/448088773.py\u001B[0m in \u001B[0;36mbackward_propagation\u001B[0;34m(self, Y_out, Y, learning_rate, mini_batch_size)\u001B[0m\n\u001B[1;32m    190\u001B[0m             \u001B[0;31m#print(f'Running backward for layer {layer.layer_name}')\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    191\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mlayer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_trainable\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 192\u001B[0;31m                 \u001B[0mdA\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlayer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdA\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlearning_rate\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    193\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    194\u001B[0m                 \u001B[0mdA\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlayer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdA\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_261026/3052592276.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(self, dZ, learning_rate)\u001B[0m\n\u001B[1;32m    308\u001B[0m                     \u001B[0mdW\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0moutput_channel_index\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mactivation_slice\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mdZ\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrow\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0mrow\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcol\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0mcol\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnewaxis\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutput_channel_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    309\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 310\u001B[0;31m                     \u001B[0mdb\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0moutput_channel_index\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdZ\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrow\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0mrow\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcol\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0mcol\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutput_channel_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    311\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    312\u001B[0m         \u001B[0;31m# unpad the dActivation_padded\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "cnn = Model()\n",
    "cnn.add(Utility.read_model_config('./input.txt', cifer_dataloader))\n",
    "cnn.compile(cost_function=CrossEntropyLoss())\n",
    "cnn.initializer_layer_params()\n",
    "cnn.train(training_data=(X_train, Y_train), epochs=10, learning_rate=0.02, test_data=(X_test, Y_test),mini_batch_size=32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}