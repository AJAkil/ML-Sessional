{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class MnistDataLoader:\n",
    "    def __init__(self, data_folder_path):\n",
    "        self.data_folder_path = data_folder_path\n",
    "        self.train_file_name = 'train-images-idx3-ubyte.gz'\n",
    "        self.train_label_file_name = 'train-labels-idx1-ubyte.gz'\n",
    "        self.test_file_name = 't10k-images-idx3-ubyte.gz'\n",
    "        self.test_label_file_name = 't10k-labels-idx1-ubyte.gz'\n",
    "        self.data = dict()\n",
    "        self.size = 28\n",
    "        self.color_channel = 1\n",
    "        self.data_list = [\n",
    "            'train_images',\n",
    "            'train_labels',\n",
    "            'test_images',\n",
    "            'test_labels'\n",
    "        ]\n",
    "\n",
    "    def load_images(self, data_list_index, file_name):\n",
    "        images = gzip.open(os.path.join(self.data_folder_path, file_name), 'rb')\n",
    "        self.data[self.data_list[data_list_index]] = np.frombuffer(images.read(), dtype=np.uint8, offset=16).reshape(-1, self.size, self.size)\n",
    "        self.data[self.data_list[data_list_index]] = self.data[self.data_list[data_list_index]].reshape(self.data[self.data_list[data_list_index]].shape[0], self.size, self.size, self.color_channel).astype(np.float32)\n",
    "\n",
    "    def load_labels(self, data_list_index, file_name):\n",
    "        labels = gzip.open(os.path.join(self.data_folder_path, file_name), 'rb')\n",
    "        self.data[self.data_list[data_list_index]] = np.frombuffer(labels.read(), dtype=np.uint8, offset=8)\n",
    "        self.data[self.data_list[data_list_index]].resize(self.data[self.data_list[data_list_index]].shape[0],1)\n",
    "\n",
    "    def load_mnist(self):\n",
    "        self.load_images(data_list_index=0, file_name=self.train_file_name)\n",
    "        self.load_labels(data_list_index=1, file_name=self.train_label_file_name)\n",
    "        self.load_images(data_list_index=2, file_name=self.test_file_name)\n",
    "        self.load_labels(data_list_index=3, file_name=self.test_label_file_name)\n",
    "\n",
    "        self.assert_data_shape()\n",
    "\n",
    "    def assert_data_shape(self):\n",
    "        assert self.data[self.data_list[0]].shape == (60000, 28, 28, 1)\n",
    "        assert self.data[self.data_list[1]].shape == (60000, 1)\n",
    "        assert self.data[self.data_list[2]].shape == (10000, 28, 28, 1)\n",
    "        assert self.data[self.data_list[3]].shape == (10000, 1)\n",
    "\n",
    "    def preprocess_data(self):\n",
    "\n",
    "        self.data[self.data_list[0]] /= 255\n",
    "        self.data[self.data_list[2]] /= 255\n",
    "\n",
    "        self.data[self.data_list[1]] = Utility.one_hot_encode(self.data[self.data_list[1]])\n",
    "\n",
    "        assert self.data[self.data_list[1]].shape == (60000, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "class Cifer10DataLoader:\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "        self.size = 32\n",
    "        self.color_channel = 3\n",
    "        self.per_batch_data_size = 10000\n",
    "        self.data = dict()\n",
    "\n",
    "    def load_data(self, file_name):\n",
    "        with open(os.path.join(self.data_path, file_name), 'rb') as f:\n",
    "\n",
    "            data_dict=pickle.load(f, encoding='latin1')\n",
    "\n",
    "            images = data_dict['data']\n",
    "            labels = data_dict['labels']\n",
    "\n",
    "            images = images.reshape(self.per_batch_data_size, self.color_channel, self.size, self.size).transpose(0,2,3,1).astype(\"float\")\n",
    "            labels = np.array(labels)\n",
    "            print(labels.shape)\n",
    "\n",
    "            return images, labels\n",
    "\n",
    "    def concatenate_data(self):\n",
    "        X1, Y1 = self.load_data('data_batch_1')\n",
    "        X2, Y2 = self.load_data('data_batch_2')\n",
    "        X3, Y3 = self.load_data('data_batch_3')\n",
    "        X4, Y4 = self.load_data('data_batch_4')\n",
    "        X5, Y5 = self.load_data('data_batch_5')\n",
    "\n",
    "        self.data['train_images'] = np.concatenate(\n",
    "            (\n",
    "                X1, X2, X3, X4, X5\n",
    "            ),\n",
    "            axis=0\n",
    "        )\n",
    "\n",
    "        self.data['train_labels'] = np.concatenate(\n",
    "            (\n",
    "                Y1.reshape(self.per_batch_data_size, 1),\n",
    "                Y2.reshape(self.per_batch_data_size, 1),\n",
    "                Y3.reshape(self.per_batch_data_size, 1),\n",
    "                Y4.reshape(self.per_batch_data_size, 1),\n",
    "                Y5.reshape(self.per_batch_data_size, 1)\n",
    "            ),\n",
    "            axis=0\n",
    "        )\n",
    "\n",
    "        X_test, Y_test = self.load_data('test_batch')\n",
    "\n",
    "        self.data['test_images'] = X_test\n",
    "        self.data['test_labels'] = Y_test.reshape(Y_test.shape[0], 1)\n",
    "\n",
    "        self.assert_data_shape()\n",
    "\n",
    "        for key, data in self.data.items():\n",
    "            print(f'Shape: {data.shape}')\n",
    "\n",
    "    def assert_data_shape(self):\n",
    "        assert self.data['train_images'].shape == (50000, 32, 32, 3)\n",
    "        assert self.data['train_labels'].shape == (50000, 1)\n",
    "        assert self.data['test_images'].shape  == (10000, 32, 32, 3)\n",
    "        assert self.data['test_labels'].shape  == (10000, 1)\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        self.data['train_images'] /= 255\n",
    "        self.data['test_images'] /= 255\n",
    "\n",
    "        self.data['train_labels'] = Utility.one_hot_encode(self.data['train_labels'])\n",
    "\n",
    "        assert self.data['train_labels'].shape == (50000, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [],
   "source": [
    "class Convolution2D:\n",
    "    def __init__(self, num_out_channel, filter_size, stride, padding_size):\n",
    "        self.num_out_channel = num_out_channel\n",
    "        self.filter_size = filter_size\n",
    "        self.stride = stride\n",
    "        self.padding_size = padding_size\n",
    "        self.h_prev, self.w_prev, self.num_channel_prev = None, None, None\n",
    "        self.h_new, self.w_new = None, None\n",
    "        self.W = None\n",
    "        self.b = None\n",
    "        self.output_tensor = None\n",
    "        self.cache = {}\n",
    "        self.relu_activation = ReLUActivation()\n",
    "\n",
    "    def initialize_output_dimensions(self, prev_layer_output_dim):\n",
    "        \"\"\"\n",
    "        Initializes output dimensions with the dimension of the previous layers\n",
    "        :param prev_layer_output_dim: output dimension of the layer immediately before this layer\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        self.h_prev, self.w_prev , self.num_channel_prev = prev_layer_output_dim\n",
    "        self.h_new = (self.h_prev - self.filter_size + 2 * self.padding_size) // self.stride + 1\n",
    "        self.w_new = (self.w_prev - self.filter_size + 2 * self.padding_size) // self.stride + 1\n",
    "\n",
    "    def initialize_weights_biases(self):\n",
    "        \"\"\"\n",
    "        Initializes weights with the proper dimensions\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.W = np.random.randn(self.filter_size, self.filter_size, self.num_channel_prev, self.num_out_channel)\n",
    "        self.b = np.random.randn(1, 1, 1, self.num_out_channel)\n",
    "\n",
    "    def forward(self, Z_prev, is_training):\n",
    "        \"\"\"\n",
    "        Performs a forward operation of the convolution layer\n",
    "        :param Z_prev: The activation of the previous layer\n",
    "        :param is_training: whether we are in training mode or not\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        assert Z_prev.shape == (self.h_prev, self.w_prev, self.num_channel_prev)\n",
    "        Z_prev = np.array(Z_prev, copy=True)\n",
    "\n",
    "        # create zero padded Z_prev\n",
    "        Z_prev_padded = Utility.zero_pad(Z_prev, self.padding_size)\n",
    "\n",
    "        # Apply convolution operation over this zero padded previous activation\n",
    "        for row in range(self.h_new):\n",
    "\n",
    "            row_start = row * self.stride\n",
    "\n",
    "            for col in range(self.w_new):\n",
    "\n",
    "                col_start = col *  self.stride\n",
    "\n",
    "                for output_channel_index in range(self.num_out_channel):\n",
    "\n",
    "                    Z_prev_windowed = Z_prev_padded[\n",
    "                        row_start : row_start + self.filter_size,\n",
    "                        col_start : col_start + self.filter_size,\n",
    "                        :\n",
    "                    ]\n",
    "\n",
    "                    conv_step_W = self.W[:, :, :, output_channel_index]\n",
    "                    conv_step_b = self.b[:, :, :, output_channel_index]\n",
    "\n",
    "                    self.output_tensor[row, col, output_channel_index] = Utility.convolve_single_step(Z_prev_windowed, conv_step_W, conv_step_b)\n",
    "\n",
    "        # asserting output shape\n",
    "        assert(self.output_tensor.shape == (self.h_new, self.w_new, self.num_out_channel))\n",
    "\n",
    "        if is_training:\n",
    "            # cache some values\n",
    "            pass\n",
    "\n",
    "        # perform activation element wise in this case\n",
    "        self.output_tensor = self.relu_activation.activation_f(self.output_tensor)\n",
    "\n",
    "    def forward_batch(self, Z_prev, is_training=True):\n",
    "        \"\"\"\n",
    "        Performs a forward operation of the convolution layer\n",
    "        :param Z_prev: The activation of the previous layer\n",
    "        :param is_training: whether we are in training mode or not\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        batch_size = Z_prev.shape[0]\n",
    "        assert Z_prev.shape == (batch_size, self.h_prev, self.w_prev, self.num_channel_prev)\n",
    "\n",
    "        self.output_tensor = np.zeros((batch_size, self.h_new, self.w_new, self.num_out_channel))\n",
    "        Z_prev = np.array(Z_prev, copy=True)\n",
    "\n",
    "        # create zero padded Z_prev\n",
    "        print(f'Z prev shape:{Z_prev.shape}')\n",
    "        Z_prev_padded = Utility.zero_pad(Z_prev, self.padding_size)\n",
    "\n",
    "        # Apply convolution operation over this zero padded previous activation\n",
    "        for image_index in range(batch_size):\n",
    "            current_Z_prev_padded = Z_prev_padded[image_index] # choosing a single tensor from the batch\n",
    "            for row in range(self.h_new):\n",
    "\n",
    "                row_start = row * self.stride\n",
    "\n",
    "                for col in range(self.w_new):\n",
    "\n",
    "                    col_start = col *  self.stride\n",
    "\n",
    "                    for output_channel_index in range(self.num_out_channel):\n",
    "\n",
    "                        Z_prev_windowed = current_Z_prev_padded[\n",
    "                                        row_start : row_start + self.filter_size,\n",
    "                                        col_start : col_start + self.filter_size,\n",
    "                                        :\n",
    "                                        ]\n",
    "\n",
    "                        conv_step_W = self.W[:, :, :, output_channel_index]\n",
    "                        conv_step_b = self.b[:, :, :, output_channel_index]\n",
    "\n",
    "                        self.output_tensor[image_index, row, col, output_channel_index] = Utility.convolve_single_step(Z_prev_windowed, conv_step_W, conv_step_b)\n",
    "\n",
    "        # asserting output shape\n",
    "        assert(self.output_tensor.shape == (batch_size, self.h_new, self.w_new, self.num_out_channel))\n",
    "        print(self.output_tensor.shape)\n",
    "\n",
    "        if is_training:\n",
    "            # cache some values\n",
    "            pass\n",
    "\n",
    "        # perform activation element wise in this case\n",
    "        self.output_tensor = self.relu_activation.activation_f(self.output_tensor)\n",
    "\n",
    "    def forward_batch_i(self, Z_prev, is_training=True):\n",
    "        \"\"\"\n",
    "        Performs a forward operation of the convolution layer\n",
    "        :param Z_prev: The activation of the previous layer\n",
    "        :param is_training: whether we are in training mode or not\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        batch_size = Z_prev.shape[0]\n",
    "        assert Z_prev.shape == (batch_size, self.h_prev, self.w_prev, self.num_channel_prev)\n",
    "\n",
    "        self.output_tensor = np.zeros((batch_size, self.h_new, self.w_new, self.num_out_channel))\n",
    "        Z_prev = np.array(Z_prev, copy=True)\n",
    "\n",
    "        # create zero padded Z_prev\n",
    "        print(f'Z prev shape:{Z_prev.shape}')\n",
    "        Z_prev_padded = Utility.zero_pad(Z_prev, self.padding_size)\n",
    "\n",
    "        # Apply convolution operation over this zero padded previous activation\n",
    "        for row in range(self.h_new):\n",
    "\n",
    "            row_start = row * self.stride\n",
    "\n",
    "            for col in range(self.w_new):\n",
    "\n",
    "                col_start = col *  self.stride\n",
    "\n",
    "                for output_channel_index in range(self.num_out_channel):\n",
    "\n",
    "                    Z_prev_windowed = Z_prev_padded[:,row_start : row_start + self.filter_size,\n",
    "                                            col_start : col_start + self.filter_size,:]\n",
    "\n",
    "                    conv_step_W = self.W[:, :, :, output_channel_index]\n",
    "                    conv_step_b = self.b[:, :, :, output_channel_index]\n",
    "\n",
    "                    # print('z shape', Z_prev_windowed.shape)\n",
    "                    # print('w shape', conv_step_W.shape)\n",
    "\n",
    "                    # self.output_tensor[:, row, col, output_channel_index] = np.sum(\n",
    "                    #     Z_prev_windowed * conv_step_W,\n",
    "                    #     axis=(1,2,3)\n",
    "                    # ) + conv_step_b\n",
    "\n",
    "                    self.output_tensor[:, row, col, output_channel_index] = Utility.convolve_single_step_over_batch(\n",
    "                        Z_prev_windowed, conv_step_W, conv_step_b\n",
    "                    )\n",
    "\n",
    "            # asserting output shape\n",
    "            assert(self.output_tensor.shape == (batch_size, self.h_new, self.w_new, self.num_out_channel))\n",
    "            print('output tensor shape:', self.output_tensor.shape)\n",
    "\n",
    "            if is_training:\n",
    "                # cache some values\n",
    "                pass\n",
    "\n",
    "            # perform activation element wise in this case\n",
    "            # self.output_tensor = self.relu_activation.activation_f(self.output_tensor)\n",
    "\n",
    "    def backward(self):\n",
    "        pass\n",
    "\n",
    "    def update_CNN_parameters(self, dW : np.array, db: np.array):\n",
    "        self.W = self.W - dW\n",
    "        self.b = self.b - db\n",
    "\n",
    "    def print_layer_dimensions(self):\n",
    "        print(f'Output Tensor Dimensions: {self.output_tensor.shape}')\n",
    "        print(f'Weight Dimension: {self.W.shape}')\n",
    "        print(f'Bias Dimension: {self.b.shape}')\n",
    "\n",
    "    def get_output_dimension(self) -> Tuple:\n",
    "        return self.h_new, self.w_new, self.num_out_channel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    def __init__(self):\n",
    "        self.input_dim = None\n",
    "        self.output_tensor = None\n",
    "        self.output_dim = None\n",
    "        self.h_prev, self.w_prev, self.num_channel_prev = None, None, None\n",
    "\n",
    "    def initialize_flatten_layer_dimensions(self, prev_layer_output_dim):\n",
    "        \"\"\"\n",
    "        :param prev_layer_output_dim: prev layer output of shape (new_h, new_w, new_channel)\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        self.h_prev, self.w_prev, self.num_channel_prev  = prev_layer_output_dim\n",
    "        self.output_dim = self.h_prev * self.w_prev * self.num_channel_prev\n",
    "\n",
    "    def forward(self, Z_prev: np.array) -> np.array:\n",
    "        self.output_tensor = Z_prev.rehsape(Z_prev.shape[0], Z_prev.shape[1] * Z_prev.shape[2] * Z_prev.shape[3])\n",
    "\n",
    "        assert self.output_tensor.shape[1] == self.output_dim\n",
    "\n",
    "    def get_output_dims(self):\n",
    "        return self.output_dim\n",
    "\n",
    "    def backward(self):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "class MaxPool:\n",
    "    def __init__(self, filter_size, stride):\n",
    "        self.filter_size = filter_size\n",
    "        self.stride = stride\n",
    "        self.h_prev, self.w_prev, self.num_channel_prev = None, None, None\n",
    "        self.h_new, self.w_new, self.num_out_channel = None, None, None\n",
    "        self.output_tensor = None\n",
    "        self.cache = {}\n",
    "\n",
    "    def initialize_max_pool_params(self, prev_layer_output_dim):\n",
    "        \"\"\"\n",
    "        Initializes output dimensions with the dimension of the previous layers\n",
    "        :param prev_layer_output_dim: output dimension of the layer immediately before this layer\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        self.h_prev, self.w_prev , self.num_channel_prev = prev_layer_output_dim\n",
    "        self.h_new = int((self.h_prev - self.filter_size) / self.stride + 1)\n",
    "        self.w_new = int((self.w_prev - self.filter_size) / self.stride + 1)\n",
    "        self.num_out_channel = self.num_channel_prev\n",
    "        self.output_tensor = np.zeros((self.h_new, self.w_new, self.num_out_channel))\n",
    "\n",
    "    def forward(self, Z_prev, is_training):\n",
    "\n",
    "        assert Z_prev.shape == (self.h_prev, self.w_prev, self.num_channel_prev)\n",
    "        Z_prev = np.array(Z_prev, copy=True)\n",
    "\n",
    "        # Apply convolution operation over this zero padded previous activation\n",
    "        for row in range(self.h_new):\n",
    "\n",
    "            row_start = row * self.stride\n",
    "\n",
    "            for col in range(self.w_new):\n",
    "\n",
    "                col_start = col *  self.stride\n",
    "\n",
    "                for output_channel_index in range(self.num_out_channel):\n",
    "\n",
    "                    Z_prev_windowed = Z_prev[\n",
    "                                      row_start : row_start + self.filter_size,\n",
    "                                      col_start : col_start + self.filter_size,\n",
    "                                      output_channel_index\n",
    "                                      ]\n",
    "\n",
    "                    self.output_tensor[row, col, output_channel_index] = Utility.get_max_pool_window(Z_prev_windowed)\n",
    "\n",
    "        assert self.output_tensor.shape == (self.h_new, self.w_new, self.num_out_channel)\n",
    "        if is_training:\n",
    "            pass\n",
    "\n",
    "    def print_layer_dimensions(self):\n",
    "        print(f'Output Tensor Dimensions: {self.output_tensor.shape}')\n",
    "\n",
    "    def backward(self):\n",
    "        pass\n",
    "\n",
    "    def get_output_dimension(self):\n",
    "        return self.h_new, self.w_new, self.num_out_channel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "class DenseLayer:\n",
    "    def __init__(self, num_units, activation_obj):\n",
    "        self.W = None\n",
    "        self.b = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "        self.num_units = num_units\n",
    "        self.cache = {}\n",
    "        self.output_tensor = None\n",
    "        self.activation_obj = activation_obj\n",
    "\n",
    "    def initialize_weights_biases(self, prev_flat_layer_output_dim):\n",
    "        self.W = np.random.randn(self.num_units, prev_flat_layer_output_dim)\n",
    "        self.b = np.random.randn(self.num_units, 1) # will be broadcast to (hidden_units, batch_size) before addition\n",
    "\n",
    "    def forward(self, Z_prev):\n",
    "        \"\"\"\n",
    "        :param Z_prev: tensor of shape (1, prev_flattened_shape)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        assert Z_prev.shape[1] == self.W.shape[1]\n",
    "\n",
    "        Z_prev = np.array(Z_prev, copy=True)\n",
    "        Z_prev = Z_prev.reshape(Z_prev.shape[1], Z_prev.shape[0])\n",
    "        self.output_tensor = self.activation_obj.activation_f(np.dot(self.W, Z_prev) + self.b)\n",
    "\n",
    "        # assert the output tensor shape should be (num_hidden_units, batch size)\n",
    "        assert self.output_tensor.shape == (self.num_units, Z_prev.shape[1])\n",
    "\n",
    "        # Perform softmax activation upon the elements\n",
    "        self.output_tensor = self.activation_obj.activation_f(self.output_tensor)\n",
    "\n",
    "\n",
    "    def backward(self):\n",
    "        pass\n",
    "\n",
    "    def get_output_dimension(self):\n",
    "        return self.output_tensor.shape[0]\n",
    "\n",
    "    def print_layer_dimensions(self):\n",
    "        print(f'Output Tensor Dimensions: {self.output_tensor.shape}')\n",
    "        print(f'Weight Dimension: {self.W.shape}')\n",
    "        print(f'Bias Dimension: {self.b.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [],
   "source": [
    "class Utility:\n",
    "\n",
    "    @staticmethod\n",
    "    def one_hot_encode(y_true):\n",
    "        # Define the One-hot Encoder\n",
    "        ohe = preprocessing.OneHotEncoder()\n",
    "        ohe.fit(y_true)\n",
    "        y_true = ohe.transform(y_true).toarray()\n",
    "        return y_true\n",
    "\n",
    "    @staticmethod\n",
    "    def zero_pad(tensor, pad_size):\n",
    "        \"\"\"\n",
    "        :param tensor: tensor of shape (batch_size, h, w, num_channel)\n",
    "        :return: padded tensor of shape (h + 2 * pad_size, w + 2 * pad_size, num_channel)\n",
    "        \"\"\"\n",
    "        return np.pad(tensor, ((0,0), (pad_size, pad_size), (pad_size, pad_size), (0,0)), mode='constant', constant_values=0)\n",
    "\n",
    "    @staticmethod\n",
    "    def convolve_single_step(Z_prev_windowed, W, b):\n",
    "        \"\"\"\n",
    "        :param Z_prev_windowed: window of shape (F, F, num_channel_Z_prev)\n",
    "        :param W: kernel/filter/weight of shape (F, F, num_channel_Z_prev)\n",
    "        :param b: bias term of shape (1, 1, 1)\n",
    "        :return: scaler convolved value\n",
    "        \"\"\"\n",
    "        return np.multiply(Z_prev_windowed, W).sum() + float(b)\n",
    "\n",
    "    @staticmethod\n",
    "    def convolve_single_step_over_batch(tensor, W, b):\n",
    "        return np.sum(tensor * W, axis=(1,2,3)) + b\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def get_max_pool_window(Z_prev_windowed):\n",
    "        return Z_prev_windowed.max()\n",
    "\n",
    "    @staticmethod\n",
    "    def create_mini_batches(X, Y, mini_batch_size):\n",
    "        total_data = X.shape[0]\n",
    "        for index in range(0, total_data, mini_batch_size):\n",
    "            start_index = index\n",
    "            end_index = min(start_index + mini_batch_size, total_data)\n",
    "            yield X[start_index: end_index,...], Y[start_index: end_index, ...]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "class ReLUActivation:\n",
    "    @staticmethod\n",
    "    def activation_f(tensor):\n",
    "        return np.max(tensor, 0)\n",
    "\n",
    "    @staticmethod\n",
    "    def d_relu(tensor):\n",
    "        return np.where(tensor > 0, 1, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class SoftmaxActivation:\n",
    "    @staticmethod\n",
    "    def activation_f(tensor):\n",
    "        exponent = np.exp(tensor)\n",
    "        return tensor/np.sum(exponent)\n",
    "\n",
    "    @staticmethod\n",
    "    def d_softmax(tensor):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class crossEntropyLoss:\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "class GradientDescent:\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def compile(self):\n",
    "        pass\n",
    "\n",
    "    def train(self):\n",
    "        pass\n",
    "\n",
    "    def predict(self):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "mnist = MnistDataLoader('./dataset/mnist')\n",
    "mnist.load_mnist()\n",
    "mnist.preprocess_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.data[mnist.data_list[1]][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "(3, 3, 3)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.randn(3,3,3,5)\n",
    "a[:,:,:,1].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(10,5,7,4) # h, w, c of previous layer\n",
    "cnn = Convolution2D(num_out_channel=8, filter_size=3, stride=2, padding_size=1)\n",
    "cnn.initialize_output_dimensions((A_prev.shape[1], A_prev.shape[2], A_prev.shape[3]))\n",
    "cnn.initialize_weights_biases()\n",
    "#cnn.print_layer_dimensions()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z prev shape:(10, 5, 7, 4)\n",
      "output tensor shape: (10, 3, 4, 8)\n",
      "output tensor shape: (10, 3, 4, 8)\n",
      "output tensor shape: (10, 3, 4, 8)\n"
     ]
    }
   ],
   "source": [
    "cnn.forward_batch_i(A_prev, is_training=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 3, 4, 8)\n",
      "Z's mean =\n",
      " 0.6923608807576933\n",
      "Z[3,2,1] =\n",
      " [-1.28912231  2.27650251  6.61941931  0.95527176  8.25132576  2.31329639\n",
      " 13.00689405  2.34576051]\n"
     ]
    }
   ],
   "source": [
    "print(cnn.output_tensor.shape)\n",
    "print(\"Z's mean =\\n\", np.mean(cnn.output_tensor))\n",
    "print(\"Z[3,2,1] =\\n\", cnn.output_tensor[3,2,1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "Output Tensor Dimensions: (3, 3, 3)\n",
      "[[[1.74481176 0.90159072 1.65980218]\n",
      "  [1.74481176 1.46210794 1.65980218]\n",
      "  [1.74481176 1.6924546  1.65980218]]\n",
      "\n",
      " [[1.14472371 0.90159072 2.10025514]\n",
      "  [1.14472371 0.90159072 1.65980218]\n",
      "  [1.14472371 1.6924546  1.65980218]]\n",
      "\n",
      " [[1.13162939 1.51981682 2.18557541]\n",
      "  [1.13162939 1.51981682 2.18557541]\n",
      "  [1.13162939 1.6924546  2.18557541]]]\n"
     ]
    }
   ],
   "source": [
    "# Case 1: stride of 1\n",
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(5, 5, 3)\n",
    "maxpool = MaxPool(filter_size=3, stride=1)\n",
    "maxpool.initialize_max_pool_params(A_prev.shape)\n",
    "maxpool.forward(A_prev, True)\n",
    "maxpool.print_layer_dimensions()\n",
    "print(maxpool.output_tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "hparameters = {\"stride\" : 1, \"f\": 3}\n",
    "\n",
    "A, cache = pool_forward(A_prev, hparameters)\n",
    "print(\"mode = max\")\n",
    "print(\"A.shape = \" + str(A.shape))\n",
    "print(\"A =\\n\", A)\n",
    "print()\n",
    "A, cache = pool_forward(A_prev, hparameters, mode = \"average\")\n",
    "print(\"mode = average\")\n",
    "print(\"A.shape = \" + str(A.shape))\n",
    "print(\"A =\\n\", A)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ True,  True])"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,23])\n",
    "b = np.array(a, copy=True)\n",
    "b == a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "(10000,)\n",
      "(10000,)\n",
      "(10000,)\n",
      "(10000,)\n",
      "(10000,)\n",
      "Shape: (50000, 32, 32, 3)\n",
      "Shape: (50000, 1)\n",
      "Shape: (10000, 32, 32, 3)\n",
      "Shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "cifer_dataloader = Cifer10DataLoader('/home/akil/Work/Work/Academics/4-2/ML/Assignment-3/dataset/cifer-10/cifar-10-python/cifar-10-batches-py')\n",
    "cifer_dataloader.concatenate_data()\n",
    "cifer_dataloader.preprocess_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifer_dataloader.data['train_labels'][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "data": {
      "text/plain": "(50000, 32, 32, 3)"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifer_dataloader.data['train_images'].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "(50000, 10)"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifer_dataloader.data['train_labels'].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "total_data = cifer_dataloader.data['train_images'].shape[0]\n",
    "mini_batch_size = 32\n",
    "p = np.random.permutation(total_data)\n",
    "cifer_dataloader.data['train_images'], cifer_dataloader.data['train_labels'] = cifer_dataloader.data['train_images'][p, :], cifer_dataloader.data['train_labels'][p, :]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "X = cifer_dataloader.data['train_images']\n",
    "Y = cifer_dataloader.data['train_labels']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(64, 32, 32, 3)\n",
      "(64, 10)\n",
      "(16, 32, 32, 3)\n",
      "(16, 10)\n"
     ]
    }
   ],
   "source": [
    "for X, Y in Utility.create_mini_batches(X, Y, mini_batch_size=64):\n",
    "    print(X.shape)\n",
    "    print(Y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}